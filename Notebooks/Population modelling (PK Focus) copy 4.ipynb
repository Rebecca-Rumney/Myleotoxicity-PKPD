{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "# Adjustables\n",
    "is_sim = True\n",
    "drug = 'large_data_1'\n",
    "num_PK_comp = 1\n",
    "observation_name = 'Platelets '\n",
    "noise_mult = 1\n",
    "data_mixed_params = [\"V_c\"]  # \n",
    "model_mixed_params = [\"V_c\", \"K_cl\"]  # \n",
    "# Data 1-pop                Profile likelihoods\n",
    "    # All - 1  2  3  4                  \n",
    "    # V_c - 1  2  3  4                   \n",
    "    # K_cl - 1  2  3  4     \n",
    "    # None - 1  2  3  4     \n",
    "# Data 2-pop\n",
    "    # All - 1  2  3  4      \n",
    "    # V_c - 1  2  3  4      \n",
    "    # K_cl - 1  2  3  4     \n",
    "    # None - 1  2  3  4     \n",
    "model_no_pooled_params = []\n",
    "model_fixed_params = [\"K_1\", \"V_1\", \"sigma_PK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folders to save to\n",
    "import os\n",
    "\n",
    "if is_sim:\n",
    "    PK_data_file = \"../Data_and_parameters/PK_sim/PK_comp\"+str(num_PK_comp)+\"/\"\n",
    "    PD_data_file = \"../Data_and_parameters/PD_sim/PK_comp\"+str(num_PK_comp)+\"/\"\n",
    "else:\n",
    "    PK_data_file = \"../Data_and_parameters/PK_real/\"\n",
    "    PD_data_file = \"../Data_and_parameters/PD_real/\"\n",
    "\n",
    "\n",
    "# Collect fixed and mixed effects params\n",
    "PK_params = [\"K_cl\", \"V_c\", \"K_1\", \"V_1\", \"K_2\", \"V_2\",  \"sigma_PK\"]\n",
    "PD_params = [\"S\", \"R_0\", \"Nonsense\", \"gamma\", \"MTT\", \"sigma_PD\"]\n",
    "all_params = (\n",
    "    [PD_params[0]] + PK_params[:2*num_PK_comp] + PD_params[1:-1] + PK_params[-1:]\n",
    "    + PD_params[-1:]\n",
    ")\n",
    "PK_params = PK_params[:2*num_PK_comp] + PK_params[-1:]\n",
    "\n",
    "PKPD_param_numbers = dict(zip(all_params, range(11)))\n",
    "PK_param_numbers = dict(zip(PK_params, range(6)))\n",
    "PKPD_pop_param_numbers = {}\n",
    "pos = 0\n",
    "for param in [x for x in all_params if (x not in model_fixed_params)]:\n",
    "    PKPD_pop_param_numbers[param] = pos\n",
    "    pos +=1\n",
    "    if param in model_mixed_params:\n",
    "        PKPD_pop_param_numbers[\"omega_\"+param] = pos\n",
    "        pos +=1\n",
    "\n",
    "PK_pop_param_numbers = {}\n",
    "pos = 0\n",
    "for param in PK_params:\n",
    "    PK_pop_param_numbers[param] = pos\n",
    "    pos +=1\n",
    "    if param in model_mixed_params:\n",
    "        PK_pop_param_numbers[\"omega_\"+param] = pos\n",
    "        pos +=1\n",
    "\n",
    "# File Name additions\n",
    "fixed_file = \"\"\n",
    "model_fixed_params = sorted(model_fixed_params)\n",
    "if len(model_fixed_params) > 0:\n",
    "    fixed_file += \"_fixed\"\n",
    "    for param in model_fixed_params:\n",
    "        fixed_file += \"_\"+param\n",
    "\n",
    "PK_pop_model_file = \"\"\n",
    "if len(model_mixed_params) == 0 and len(model_no_pooled_params) == 0:\n",
    "    PK_pop_model_file += \"fixed_effects\"\n",
    "else:\n",
    "    PK_pop_model_file += \"pop\"\n",
    "    for param in model_mixed_params:\n",
    "        if param in PK_params:\n",
    "            PK_pop_model_file += \"_\"+param\n",
    "    if len(model_no_pooled_params) > 0:\n",
    "        PK_pop_model_file += \"_independ\"\n",
    "        for param in model_no_pooled_params:\n",
    "            if param in PK_params:\n",
    "                PK_pop_model_file += \"_\"+param\n",
    "\n",
    "PD_pop_model_file = \"\"\n",
    "if len(model_mixed_params) == 0 and len(model_no_pooled_params) == 0:\n",
    "    PD_pop_model_file += \"fixed_effects\"\n",
    "else:\n",
    "    PD_pop_model_file += \"pop\"\n",
    "    for param in model_mixed_params:\n",
    "        PD_pop_model_file += \"_\"+param\n",
    "    if len(model_no_pooled_params) > 0:\n",
    "        PD_pop_model_file += \"_independ\"\n",
    "        for param in model_no_pooled_params:\n",
    "            PD_pop_model_file += \"_\"+param\n",
    "\n",
    "if is_sim:\n",
    "    if len(data_mixed_params)==0:\n",
    "        drug += \"_no_pop\"\n",
    "    else:\n",
    "        drug += \"_\"+str(len(data_mixed_params))+\"pop\"\n",
    "    if noise_mult != 1:\n",
    "        drug += \"_small_noise_\"+str(noise_mult)\n",
    "\n",
    "\n",
    "PK_image_file = \"../Images/PK_sim/PK_comp\"+str(num_PK_comp)+\"/\"+drug\n",
    "PD_image_file = \"../Images/PD_sim/PD_comp\"+str(num_PK_comp)+\"/\"+drug\n",
    "mono_file = \"../Monolix/PK_sim/PK_comp\"+str(num_PK_comp)+\"/\"+drug\n",
    "\n",
    "os.makedirs(PK_data_file+drug, exist_ok=True)\n",
    "os.makedirs(PD_data_file+drug, exist_ok=True)\n",
    "os.makedirs(PK_image_file, exist_ok=True)\n",
    "os.makedirs(PD_image_file, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PK Analysis\n",
    "\n",
    "For the simulated dataset, we need to acquire the data generating parameters. Typical values are the same from the poooled analysis, so we will load those results. The values for $\\Omega$ we have to set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PK_true_param():\n",
    "    PK_comp2_true_typs = np.load(\"/home/rumney/Documents/Myleotoxicity/Myleotoxicity-PKPD/Data_and_parameters/PK_sim/PK_comp2/actual_params.npy\")[1]\n",
    "    PK_comp2_true_typs = PK_comp2_true_typs.astype(float)\n",
    "\n",
    "    if num_PK_comp==1:\n",
    "        PK_comp_vols = [['V_c, L'], [PK_comp2_true_typs[1]+PK_comp2_true_typs[3]]]\n",
    "    else:\n",
    "        PK_comp_vols = [\n",
    "            ['V_c, L']+['V_'+str(x)+', L' for x in range(1, num_PK_comp)],\n",
    "            [PK_comp2_true_typs[1]]+[PK_comp2_true_typs[3]/num_PK_comp]*num_PK_comp\n",
    "        ]\n",
    "    PK_rates = [\n",
    "        ['K_{cl}, L/hr'] + ['K_'+str(x)+', L/hr' for x in range(1, num_PK_comp)],\n",
    "        [PK_comp2_true_typs[0]] + [PK_comp2_true_typs[3]/x for x in range(1, num_PK_comp)]\n",
    "    ]\n",
    "\n",
    "    PK_true_typs = np.empty((2, 2*num_PK_comp+1), dtype='<U32')\n",
    "    PK_true_typs[:, 0:-1:2] = PK_rates\n",
    "    PK_true_typs[:, 1:-1:2] = PK_comp_vols\n",
    "    PK_true_typs[:, -1] = ['sigma_{m, PK}', PK_comp2_true_typs[-1]]\n",
    "\n",
    "    # PK_true_typs[1, 0] = 0.5*float(PK_true_typs[1, 0])\n",
    "    np.save(PK_data_file+\"actual_params.npy\", PK_true_typs)\n",
    "\n",
    "    PK_true_omegas = [0.3]*(num_PK_comp+1)\n",
    "    np.save(PK_data_file+\"omega.npy\", PK_true_omegas)\n",
    "\n",
    "    return PK_true_typs, PK_true_omegas\n",
    "\n",
    "# Set the bounds on the parameters\n",
    "# bounds = np.asarray([\n",
    "#     [\n",
    "#         0.01,\n",
    "#         0.1*V_c_approx,\n",
    "#         # 0.01,\n",
    "#         # 0.01*V_c_approx,\n",
    "#         0.0001\n",
    "#     ],\n",
    "#     [\n",
    "#         100,\n",
    "#         10*V_c_approx,\n",
    "#         # 100,\n",
    "#         # 100*V_c_approx,\n",
    "#         1\n",
    "#     ]\n",
    "# ])\n",
    "\n",
    "# np.save(PK_data_file+\"bounds.npy\", bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import figure_factory as ff\n",
    "from pandas.core.dtypes.common import is_integer\n",
    "\n",
    "try:\n",
    "    # Load the Data-generating typical parameters\n",
    "    PK_true_typs = np.load(PK_data_file+\"actual_params.npy\")\n",
    "\n",
    "    # Load the Data-generating inter-individual variability parameters\n",
    "    PK_true_omegas = np.load(PK_data_file+\"omega.npy\")\n",
    "except FileNotFoundError:\n",
    "    PK_true_typs, PK_true_omegas = create_PK_true_param()\n",
    "\n",
    "split_param_names = np.char.split(PK_true_typs[0, :], \", \")\n",
    "PK_true_pops = PK_true_typs\n",
    "for param in PK_params:\n",
    "    pos_typ = PK_param_numbers[param]\n",
    "    pos_pop = PK_pop_param_numbers[param]\n",
    "    if param in data_mixed_params:\n",
    "        omega = PK_true_omegas[pos_typ]\n",
    "    else:\n",
    "        omega = 1e-5\n",
    "\n",
    "    if param in model_mixed_params:\n",
    "        PK_true_pops = np.insert(\n",
    "            PK_true_pops,\n",
    "            pos_pop+1,\n",
    "            [\"omega_{\"+split_param_names[pos_typ][0]+\"}\", omega],\n",
    "            axis=1\n",
    "        )\n",
    "        PK_true_pops[0, pos_pop] = str().join(\n",
    "            [split_param_names[pos_typ][0], \"_typ\", \", \"]\n",
    "            + list(split_param_names[pos_typ][1:])\n",
    "        )\n",
    "\n",
    "PK_true_pops[1, -1] = noise_mult*float(PK_true_pops[1, -1])\n",
    "# PK_bounds = np.load(PK_data_file+\"bounds.npy\")\n",
    "\n",
    "table_df = pandas.DataFrame(\n",
    "    PK_true_pops.transpose(),\n",
    "    columns=['Parameter name', 'Data generating value']\n",
    ")\n",
    "table_df = table_df.astype({'Data generating value': float})\n",
    "\n",
    "table_df = table_df.round({'Data generating value': 4})\n",
    "table_df = table_df.set_index('Parameter name').transpose()\n",
    "fig = ff.create_table(table_df)\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    height=45,\n",
    ")\n",
    "\n",
    "pop_param_names = PK_true_pops[0, :]\n",
    "PK_true_pops = PK_true_pops[1, :].astype('float64')\n",
    "\n",
    "PK_param_names = PK_true_typs[0, :]\n",
    "PK_true_typs = PK_true_typs[1, :].astype('float64')\n",
    "\n",
    "fig.write_image(PK_image_file+\"/true_values.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.PK_model import ChiPKLin\n",
    "import chi\n",
    "import logging\n",
    "\n",
    "# Remove Annoying logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Set up the model\n",
    "PK_model = ChiPKLin(num_comp=num_PK_comp)\n",
    "PK_model.set_administration(\n",
    "    compartment='central', amount_var='drug_amount')\n",
    "PK_model.set_outputs(['central.drug_concentration'])\n",
    "noise_model = chi.MultiplicativeGaussianErrorModel()\n",
    "n_noise = noise_model.n_parameters()\n",
    "chi_param_names = np.concatenate((PK_model.parameters(), noise_model.get_parameter_names()))\n",
    "\n",
    "pop_models = []\n",
    "for i_param, param in enumerate(PK_params):\n",
    "    chi_param = chi_param_names[i_param]\n",
    "    if param in model_mixed_params:\n",
    "        print(chi_param, \"mixed\")\n",
    "        pop_models.append(chi.LogNormalModel(n_dim=1))\n",
    "    elif param in model_no_pooled_params:\n",
    "        print(chi_param, \"no pooled\")\n",
    "        pop_models.append(chi.HeterogeneousModel(n_dim=1))\n",
    "    else:\n",
    "        print(chi_param, \"pooled\")\n",
    "        pop_models.append(chi.PooledModel(n_dim=1))\n",
    "\n",
    "population_model = chi.ComposedPopulationModel(pop_models)\n",
    "\n",
    "# Set up the inference problem\n",
    "problem = chi.ProblemModellingController(PK_model, noise_model)\n",
    "problem.set_population_model(population_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PK_dataset(dose_amts, n_ids_per_dose, times, dose_time=0):\n",
    "    n_ids_data = n_ids_per_dose*len(dose_amts)\n",
    "\n",
    "    # Get log of mixed effect typical parameters\n",
    "    pop_params = PK_true_pops.copy()\n",
    "    for param in PK_params:\n",
    "        if param in model_mixed_params:\n",
    "            pos = PK_pop_param_numbers[param]\n",
    "            pop_params[pos] = np.log(pop_params[pos])\n",
    "    \n",
    "    # Acquire patient parameters\n",
    "    individual_parameters = population_model.sample(\n",
    "        parameters=pop_params,\n",
    "        n_samples=n_ids_data\n",
    "    )\n",
    "\n",
    "    # Set up Dataframe\n",
    "    df = pandas.DataFrame(columns=[\n",
    "        \"ID\", \"Time\", \"Observable\", \"Value\", \"Dose group\", \"Duration\", \"Dose\"\n",
    "    ])\n",
    "    # Generate data\n",
    "    for i_dose, dose in enumerate(dose_amts):\n",
    "        PK_model.set_dosing_regimen(dose=dose, start=dose_time, period=0)\n",
    "        for i_ind in range(0, n_ids_per_dose):\n",
    "            # Simulate model\n",
    "            pat_param = individual_parameters[i_ind+i_dose, :]\n",
    "            patient_result = PK_model.simulate(pat_param[:-n_noise], times)\n",
    "            patient_result = noise_model.sample(\n",
    "                pat_param[-n_noise:], patient_result[0, :]\n",
    "            )[:, 0]\n",
    "\n",
    "            # Format patient data\n",
    "            patient_data= pandas.DataFrame(columns=[\n",
    "                \"ID\", \"Time\", \"Observable\", \"Value\", \"Dose group\", \"Duration\", \"Dose\"\n",
    "            ])\n",
    "            patient_id = i_ind+(i_dose*n_ids_per_dose)+1\n",
    "            patient_data[\"ID\"] = [patient_id]*(len(times)+1)\n",
    "            patient_data[\"Time\"] = np.concatenate((times, [dose_time]))\n",
    "            patient_data[\"Observable\"] = (\n",
    "                ['central.drug_concentration']*len(times)+[None]\n",
    "            )\n",
    "            patient_data[\"Value\"] = np.concatenate((patient_result, [None]))\n",
    "            patient_data[\"Dose group\"] = [dose]*(len(times)+1)\n",
    "            patient_data[\"Duration\"] = [None]*len(times)+[0.01]\n",
    "            patient_data[\"Dose\"] = [None]*len(times)+[dose]\n",
    "\n",
    "            # Join to main dataframe\n",
    "            df = pandas.concat([df, patient_data])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "    return df, individual_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_sim:\n",
    "    PK_true_ind = {}\n",
    "    # Check whether Dataset already exists\n",
    "    try:\n",
    "        df = pandas.read_csv(PD_data_file + drug+\"/data.csv\")\n",
    "        df.drop(\n",
    "            df.loc[df['Observable'] == 'circulating.R'].index, inplace=True\n",
    "        )\n",
    "        dose_time = (df.loc[df['Dose'].notna()])['Time'].min()\n",
    "        df['Time'] = df['Time']-dose_time\n",
    "        df.replace(\n",
    "            {'PK_central.drug_concentration': 'central.drug_concentration'},\n",
    "            inplace=True\n",
    "        )\n",
    "        for param in data_mixed_params:\n",
    "            pos = PK_param_numbers[param]\n",
    "            PK_true_ind[param] = np.load(PD_data_file + drug + \"/ind_\" + param + \".npy\")\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            df = pandas.read_csv(PK_data_file + drug+\"/data.csv\")\n",
    "            os.makedirs(mono_file, exist_ok=True)\n",
    "            df_mono = df.copy()\n",
    "            df_mono.replace(\n",
    "                {'central.drug_concentration': 'central_drug_conc'},\n",
    "                inplace=True\n",
    "            )\n",
    "            df_mono.to_csv(mono_file + \"/data.csv\", index=False)\n",
    "            for param in data_mixed_params:\n",
    "                pos = PK_param_numbers[param]\n",
    "                PK_true_ind[param] = np.load(PK_data_file + drug + \"/ind_\" + param + \".npy\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"creating new dataset\")\n",
    "            # Select options for data\n",
    "            dose_amts = [1.0, 2.0, 3.0]\n",
    "            n_ids_per_dose = 15\n",
    "            n_times_data = 50\n",
    "\n",
    "            # Create and save simulated data\n",
    "            times = np.linspace(0.05, 5, n_times_data)\n",
    "            df, ind_params = create_PK_dataset(\n",
    "                dose_amts, n_ids_per_dose, times\n",
    "            )\n",
    "            df.to_csv(PK_data_file + drug+\"/data.csv\", index=False)\n",
    "\n",
    "            os.makedirs(mono_file, exist_ok=True)\n",
    "            df_mono = df.copy()\n",
    "            df_mono.replace(\n",
    "                {'central.drug_concentration': 'central_drug_conc'},\n",
    "                inplace=True\n",
    "            )\n",
    "            df_mono.to_csv(mono_file + \"/data.csv\", index=False)\n",
    "            for param in data_mixed_params:\n",
    "                pos = PK_param_numbers[param]\n",
    "                np.save(\n",
    "                    PK_data_file + drug + \"/ind_\" + param + \".npy\",\n",
    "                    ind_params[:, pos]\n",
    "                )\n",
    "                PK_true_ind[param] = ind_params[:, pos]\n",
    "\n",
    "else:\n",
    "    # Load in the data\n",
    "    df = pandas.read_csv(PK_data_file + drug+\"/data.csv\")\n",
    "    dose_unit = \"mg\"\n",
    "\n",
    "    # Reformat this into Something Chi understands\n",
    "    df = df.rename(columns={\n",
    "        'TIME': 'Time', 'OBS': 'Value', 'DOSE': 'Dose group'\n",
    "    })\n",
    "    df.replace(\n",
    "        {drug: 'central.drug_concentration'},\n",
    "        inplace=True\n",
    "    )\n",
    "    dosing_df = df.groupby('ID', as_index=False)['Dose group'].mean()\n",
    "    dosing_df.columns = ['ID', 'Dose']\n",
    "    dosing_df['Time'] = [0.0]*len(dosing_df)\n",
    "    dosing_df['Duration'] = [0.001]*len(dosing_df)\n",
    "\n",
    "    df = pandas.concat([df, dosing_df], join='outer', ignore_index=True)\n",
    "\n",
    "df_obs = df.loc[df['Observable'] == 'central.drug_concentration']\n",
    "df = df.loc[df['ID'].isin(df_obs['ID'].unique())]\n",
    "n_ids_data = len(df[\"ID\"].unique())\n",
    "\n",
    "dose_unit = \"mg\"\n",
    "problem.set_data(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin with the parameter inference we can make some estimations of the parameter values. This ensures we have the correct scale of these parameters and helps us with determining the priors and starting points for the maximum posterior method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Find the first and second points for each individual\n",
    "df_dose = np.asarray(df.groupby('ID')['Dose'].first())\n",
    "df_obs['rank'] = df_obs.sort_values('Time').groupby('ID').cumcount()+1\n",
    "points_1st = df_obs[df_obs['rank'] == 1].sort_values('ID', ignore_index=True)\n",
    "points_2nd = df_obs[df_obs['rank'] == 2].sort_values('ID', ignore_index=True)\n",
    "\n",
    "# Determine y-intercept\n",
    "y_0 = points_1st['Value'] - points_1st['Time'] * (\n",
    "    (points_1st['Value'] - points_2nd['Value'])\n",
    "    / (points_1st['Time'] - points_2nd['Time'])\n",
    ")\n",
    "# Estimate V_c\n",
    "V_c_approx = (df_dose/y_0).mean()\n",
    "\n",
    "# Determine the AUC from the first to last point,\n",
    "AUC_0_last = np.empty(len(df[\"ID\"].unique()))\n",
    "# and the last drug concentration value,\n",
    "C_last = np.empty(len(df[\"ID\"].unique()))\n",
    "# and the rate of decay of the drug,\n",
    "lambda_z = np.empty(len(df[\"ID\"].unique()))\n",
    "\n",
    "for i, patient in enumerate(df[\"ID\"].unique()):\n",
    "    y_ind = np.asarray(df_obs.loc[df_obs['ID'] == patient]['Value'])\n",
    "    x_ind = np.asarray(df_obs.loc[df_obs['ID'] == patient]['Time'])\n",
    "    AUC_0_last[i] = simpson(y=y_ind, x=x_ind)\n",
    "    C_last[i] = y_ind[-1]\n",
    "    lambda_z[i] = linregress(\n",
    "        x=x_ind[int(0.5*len(x_ind)):],\n",
    "        y=x_ind[int(0.5*len(x_ind)):]\n",
    "    ).slope\n",
    "\n",
    "# Extrapolate AUC_0_last to infinity\n",
    "AUC_inf = AUC_0_last+C_last/lambda_z\n",
    "# Approximate the clearance\n",
    "cl_approx = (df_dose/AUC_inf).mean()\n",
    "\n",
    "Approximations = [\n",
    "        cl_approx,          # Clearance\n",
    "        V_c_approx          # Central volume\n",
    "    ]+[\n",
    "        cl_approx,          # Periferal compartment transfer\n",
    "        V_c_approx          # Periferal compartment volume\n",
    "    ]*(num_PK_comp-1)+[\n",
    "        0.1,                # PK Noise parameter\n",
    "]\n",
    "\n",
    "table_df.loc[\"Approximate\"] = [np.nan]*len(table_df.columns)\n",
    "for i, param in enumerate(PK_params):\n",
    "    pos = PK_pop_param_numbers[param]\n",
    "    table_df.iat[1, pos] = Approximations[i]\n",
    "table_df = table_df.round(4)\n",
    "\n",
    "fig = ff.create_table(table_df, index=True)\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    height=65\n",
    ")\n",
    "# fig.write_image(PK_image_file+\"/data_table.svg\")\n",
    "fig.show()\n",
    "\n",
    "# Determine the shape parameters for the priors\n",
    "shape_parameters = [\n",
    "        0.3,                       # Clearance\n",
    "        0.3,                        # Central volume\n",
    "    ]+[\n",
    "        3,                          # Periferal compartment transfer\n",
    "        0.6,                        # Periferal compartment volume\n",
    "    ]*(num_PK_comp-1)+[\n",
    "        0.4,                        # PK Noise parameter\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "\n",
    "# Build the priors and transformation of the parameter space\n",
    "log_priors = []\n",
    "transformations = []\n",
    "for param in PK_params:\n",
    "    if param in model_mixed_params:\n",
    "        # Prior for the typical value\n",
    "        approx = np.log(Approximations[PK_param_numbers[param]])\n",
    "        shape = shape_parameters[PK_param_numbers[param]]\n",
    "        log_priors.append(pints.GaussianLogPrior(approx, shape))\n",
    "        # Prior for omega\n",
    "        approx = np.log(shape_parameters[PK_param_numbers[param]])\n",
    "        log_priors.append(pints.LogNormalLogPrior(approx, 0.2))\n",
    "        # Transformation for the individual parameters\n",
    "        ind_trans = pints.LogTransformation(n_ids_data)\n",
    "        transformations = [ind_trans] + transformations\n",
    "        # Transformation for the population parameters\n",
    "        transformations.append(pints.IdentityTransformation(2))\n",
    "    else:\n",
    "        # Prior and transformation for the pooled parameter\n",
    "        approx = np.log(Approximations[PK_param_numbers[param]])\n",
    "        shape = shape_parameters[PK_param_numbers[param]]\n",
    "        log_priors.append(pints.LogNormalLogPrior(approx, shape))\n",
    "        transformations.append(pints.LogTransformation(1))\n",
    "\n",
    "# Compose the priors together\n",
    "log_prior = pints.ComposedLogPrior(*log_priors)\n",
    "problem.set_log_prior(log_prior)\n",
    "\n",
    "# Compose the transformations together\n",
    "transformation = pints.ComposedTransformation(*transformations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "\n",
    "pop_parameters = PK_true_pops.copy()\n",
    "plot_ind = {}\n",
    "for param in model_mixed_params:\n",
    "    pos = PK_pop_param_numbers[param]\n",
    "    pop_parameters[pos] = np.log(pop_parameters[pos])\n",
    "    pos = PK_param_numbers[param]\n",
    "    if param in data_mixed_params:\n",
    "        plot_ind[chi_param_names[pos]] = PK_true_ind[param]\n",
    "\n",
    "plot = Plot_Models(population_model, noise_model, PK_model, log_prior)\n",
    "plot.set_data(df)\n",
    "fig = plot.plot_pop_distribution(\n",
    "    pop_parameters, plot_ind\n",
    ")\n",
    "# fig.write_image(\n",
    "#     image_file + \"PK_\"+drug+\"/\"\n",
    "#     +PD_pop_model_file+\"_population_distribution.svg\"\n",
    "# )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = []\n",
    "upper = []\n",
    "PK_bounds =  np.load(PK_data_file+\"bounds.npy\")\n",
    "i = 0\n",
    "for i, param in enumerate(PK_params):\n",
    "    if param in model_mixed_params:\n",
    "        lower.append(np.log(PK_bounds[0, i]))\n",
    "        upper.append(np.log(PK_bounds[1, i]))\n",
    "\n",
    "        lower.append(0)\n",
    "        upper.append(1.2)\n",
    "    else:\n",
    "        lower.append(0)\n",
    "        upper.append(PK_bounds[1, i])\n",
    "\n",
    "fig = plot.plot_prior(bounds=(lower, upper))\n",
    "# fig.write_image(\n",
    "#     PK_image_file + \"/\" + PD_pop_model_file + \"_hyperpriors.svg\"\n",
    "# )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Plot_Models(population_model, noise_model, PK_model, log_prior, data=df)\n",
    "fig = plot.plot_over_time(PK_true_pops, show_data=True, title=\"Data\")\n",
    "fig.write_image(\n",
    "    PK_image_file + \"/\" + PK_pop_model_file + \"_data.svg\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum A Posteriori method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "log_posterior = problem.get_log_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Inference import OptimisationController\n",
    "from plotly import figure_factory as ff\n",
    "\n",
    "# Set the start point for optimisation\n",
    "start_point = np.asarray(Approximations)\n",
    "\n",
    "n_mix = 0\n",
    "for param in PK_params:\n",
    "    if param in model_mixed_params:\n",
    "        pos = PK_pop_param_numbers[param]\n",
    "        start_point[pos] = np.log(start_point[pos])\n",
    "        start_point = np.insert(start_point, pos+1, 0.4)\n",
    "        n_mix +=1\n",
    "\n",
    "\n",
    "# Optimise the model with respect to the data\n",
    "optimisation = OptimisationController(\n",
    "    log_posterior\n",
    ")\n",
    "optimisation.set_n_runs(n_runs*10)\n",
    "initial_params = optimisation._initial_params\n",
    "\n",
    "i = 0\n",
    "for ini_param in initial_params:\n",
    "    print(i, ini_param[n_mix*n_ids_data:])\n",
    "    if pandas.isna(log_posterior(ini_param)):\n",
    "        for j, param in enumerate(ini_param):\n",
    "            test_param = ini_param.copy()\n",
    "            test_param[j] = 0.5*param\n",
    "            if not pandas.isna(log_posterior(test_param)):\n",
    "                print(\"parameter \"+str(j-n_ids_data)+\" too large: \"+str(param))\n",
    "            test_param[j] = 1.5*param\n",
    "            if not pandas.isna(log_posterior(test_param)):\n",
    "                print(\"parameter \"+str(j-n_ids_data)+\" too small: \"+str(param))\n",
    "        initial_params = np.delete(initial_params, i, axis=0)\n",
    "    else:\n",
    "        i += 1\n",
    "        if i >= n_runs-1:\n",
    "            print(\"successful\")\n",
    "            break\n",
    "\n",
    "optimisation.set_n_runs(n_runs)\n",
    "optimisation.set_initial_point([1], [start_point])\n",
    "optimisation.set_initial_point(\n",
    "    range(2, n_runs+1),\n",
    "    initial_params[:n_runs-1, n_mix*n_ids_data:],\n",
    "    initial_params[:n_runs-1, :n_mix*n_ids_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation.set_optimiser(pints.CMAES)\n",
    "optimisation.set_transform(transformation)\n",
    "optimisation.set_parallel_evaluation(True)\n",
    "result = optimisation.run(show_run_progress_bar=False, log_to_screen=False)\n",
    "\n",
    "# Show summary of optimisation\n",
    "print('Log-Posterior Value: \\t'+str(result['Score'].unique()))\n",
    "time = np.asarray(result['Time'].unique())\n",
    "print('Time Taken: \\t'+str((time/60).astype(int))+\" minutes, \"+str((time%60).astype(int))+\" seconds, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pop_params = np.empty((n_runs, len(start_point)))\n",
    "opt_ind_params = np.empty((\n",
    "    n_runs, n_ids_data*len(model_mixed_params)\n",
    "))\n",
    "column_names = ['Parameter']\n",
    "for run in range(1, n_runs+1):\n",
    "    column_names.append('Run ' + str(run))\n",
    "    run_res = result.loc[result['Run'] == run]\n",
    "    opt_pop_params[run-1] = run_res.loc[run_res['ID'].isnull()]['Estimate'].values\n",
    "    opt_ind_params[run-1] = run_res.dropna(subset=['ID'])['Estimate'].values\n",
    "\n",
    "scores = np.transpose([result.groupby([\"Run\"])['Score'].first()])\n",
    "column_names = column_names + ['Mean', 'True']\n",
    "summary_data = np.concatenate((\n",
    "    [np.concatenate((pop_param_names, [\"Log-posterior\"]))],\n",
    "    np.concatenate((opt_pop_params, scores), axis=1),\n",
    "    [np.concatenate((np.mean(opt_pop_params, axis=0), [np.NaN]))],\n",
    "    [np.concatenate((PK_true_pops, [np.NaN]))]\n",
    "), axis=0)\n",
    "summary_df = pandas.DataFrame(summary_data.transpose(), columns=column_names)\n",
    "\n",
    "\n",
    "summary_df.to_csv(\n",
    "    PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_pop.csv\", index=False\n",
    ")\n",
    "np.save(PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_ind.npy\", opt_ind_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ind_params = np.load(PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_ind.npy\")\n",
    "summary_df = pandas.read_csv(\n",
    "    PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_pop.csv\"\n",
    ")\n",
    "summary_df = summary_df.set_index(\"Parameter\")\n",
    "\n",
    "print('Result:')\n",
    "table_df = summary_df.copy()\n",
    "table_df = table_df.transpose()\n",
    "n_runs = len(table_df)-2\n",
    "for param in model_mixed_params:\n",
    "    if param in PK_params:\n",
    "        pos = PK_pop_param_numbers[param]\n",
    "        col = pop_param_names[pos]\n",
    "        param_typ = np.asarray(table_df[col])\n",
    "        param_typ[:-1] = np.exp(param_typ[:-1])\n",
    "        table_df[col] = param_typ\n",
    "rounding = dict(zip(table_df.columns, [3]*6))\n",
    "rounding[\"Log-posterior\"] = 2\n",
    "table_df = table_df.round(rounding)\n",
    "fig = ff.create_table(table_df, index=True)\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=250,\n",
    ")\n",
    "# fig.write_image(PK_image_file+'/'+PK_pop_model_file+\"_opt_table.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "\n",
    "log_posterior_values = summary_df.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "log_posterior_values = np.asarray(log_posterior_values)\n",
    "\n",
    "converged = np.bitwise_and((log_posterior_values>=(np.sort(log_posterior_values)[-2]+np.log(0.02))), (log_posterior_values<=(np.sort(log_posterior_values)[-2]-np.log(0.02))))\n",
    "summary_reduced = summary_df.copy()\n",
    "summary_reduced = summary_reduced.iloc[:, :-2]\n",
    "summary_reduced = summary_reduced.loc[:, np.logical_not(converged)]\n",
    "mean_of_converged = summary_df.iloc[:, :-2].loc[:, converged].mean(axis=1)\n",
    "summary_reduced[\"Mean of converged\"] = mean_of_converged\n",
    "summary_reduced[\"True\"] = summary_df[\"True\"]\n",
    "\n",
    "table = summary_reduced.copy().transpose()\n",
    "i_mix = 0\n",
    "n_mix = len([n for n in model_mixed_params if n in PK_params])\n",
    "ind_params = np.empty((n_ids_data, len(summary_reduced) - 1 - n_mix))\n",
    "for param in PK_params:\n",
    "    pos_pop = PK_pop_param_numbers[param]\n",
    "    pos_typ =  PK_param_numbers[param]\n",
    "    if param in model_mixed_params:\n",
    "        col = pop_param_names[pos_pop]\n",
    "        param_typ = np.asarray(table[col])\n",
    "        param_typ[:-1] = np.exp(param_typ[:-1])\n",
    "        table[col] = param_typ\n",
    "\n",
    "        ind_params[:, pos_typ] = opt_ind_params[converged, i_mix::n_mix].mean(axis=0)\n",
    "        i_mix += 1\n",
    "    else:\n",
    "        ind_params[:, pos_typ] = summary_reduced[\"Mean of converged\"].iat[pos_pop]\n",
    "\n",
    "plot_pop_params = {\"Mean of converged\": table.loc[\"Mean of converged\"]}\n",
    "plot_ind_params = {\"Mean of converged\": ind_params}\n",
    "\n",
    "\n",
    "for i_run, run in enumerate(summary_reduced.columns[:-2]):\n",
    "    run_pop_params = table.loc[run]\n",
    "    plot_pop_params[\"Failed \" + run] = run_pop_params[:-1]\n",
    "    ind_params = np.empty((n_ids_data, len(summary_reduced) - 1 - n_mix))\n",
    "    i_mix = 0\n",
    "    for param, pos in PK_param_numbers.items():\n",
    "        if param in model_mixed_params:\n",
    "            ind_params[:, pos] = opt_ind_params[np.logical_not(converged), i_mix::n_mix][i_run]\n",
    "            i_mix += 1\n",
    "        else:\n",
    "            ind_params[:, pos] = run_pop_params[pos + i_mix]\n",
    "    plot_ind_params[\"Failed \" + run] = ind_params\n",
    "\n",
    "rounding = dict(zip(table.columns, [3]*6))\n",
    "rounding[\"Log-posterior\"] = 2\n",
    "table = table.round(rounding)\n",
    "fig = ff.create_table(table, index=True)\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    ")\n",
    "fig.write_image(PK_image_file+'/'+PK_pop_model_file+\"_opt_table.svg\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "plot = Plot_Models(\n",
    "    pop_model=population_model,\n",
    "    error_models=noise_model,\n",
    "    mech_model=PK_model,\n",
    "    data=df\n",
    ")\n",
    "\n",
    "fig = plot.plot_over_time(plot_pop_params, ind_params=plot_ind_params, show_data=True, doses=None, title=\"MLP Prediction\", highlight_first=True)\n",
    "fig.write_image(PK_image_file+\"/\"+PK_pop_model_file+\"opt_graph.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Likelihood over the Parameter Space\n",
    "\n",
    "To determine potential identifiability problems in optimisation, we need to view the likelihood score over the parameter space around the optimum. To do this initially, I will view 1d & 2d slices of the parameter space, which pass through the optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_posterior = problem.get_log_posterior()\n",
    "log_likelihood = log_posterior.get_log_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ind_params = np.load(PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_ind.npy\")\n",
    "summary_df = pandas.read_csv(\n",
    "    PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_pop.csv\"\n",
    ")\n",
    "summary_df = summary_df.set_index(\"Parameter\")\n",
    "\n",
    "log_posterior_values = summary_df.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "log_posterior_values = np.asarray(log_posterior_values)\n",
    "\n",
    "best = log_posterior_values==(np.max(log_posterior_values))\n",
    "pop_best_of_converged = np.asarray(summary_df.iloc[:-1, :-2].loc[:, best]).flatten()\n",
    "ind_best_of_converged = opt_ind_params[best].flatten()\n",
    "\n",
    "ref_param = np.concatenate((ind_best_of_converged, pop_best_of_converged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = np.asarray(ref_param)\n",
    "bottom_parameters = ind_best_of_converged\n",
    "top_parameters = pop_best_of_converged\n",
    "\n",
    "# Broadcast pooled parameters and reshape bottom parameters to\n",
    "# (n_ids, n_dim)\n",
    "bottom_parameters = \\\n",
    "    log_likelihood._population_model.compute_individual_parameters(\n",
    "        parameters=top_parameters,\n",
    "        eta=bottom_parameters,\n",
    "        return_eta=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mono_start = np.asarray([\n",
    "#     [0.683, 1.426, 1, 0.3],\n",
    "#     [1, 1, 1, 1],\n",
    "#     [1, 1, 1, 1]\n",
    "# ])\n",
    "\n",
    "# mono_params = np.asarray(\n",
    "#     ['V_c_pop', 'Cl_pop', 'omega_V_c', 'omega_cl', 'sigma_m']\n",
    "# )\n",
    "# mono_order = [1, 3, 0, 2, -1]\n",
    "# # np.save(mono_file+drug+'/'+PK_pop_model_file+\"_param_reorder.npy\", mono_order)\n",
    "\n",
    "# mono_order = np.load(mono_file+drug+'/'+PK_pop_model_file+2\"_param_reorder.npy\")\n",
    "# print(log_posterior.get_parameter_names(exclude_bottom_level=True))\n",
    "# print(mono_params[mono_order])\n",
    "# mono_runs = {}\n",
    "\n",
    "# mono_runs['All mixed-effects'] = np.asarray([\n",
    "#     [0.6724021855, 1.4025881404, 0.2091850911, 0.02255928739, 0.09698379049],\n",
    "#     [0.6719967763, 1.4016972075, 0.213069647, 0.01770235678, 0.0970284138]\n",
    "# ])[:, mono_order]\n",
    "\n",
    "# mono_runs['V_c'] = np.asarray([[2.935460741, 0.2217901089, 5.5304756874, 0.2282212677, 0.09230391296],\n",
    "#     2.9336475614\t0.2215255612\t5.5241375691\t0.2289263105\t0.09221970779\n",
    "#     2.9341357982\t0.2213419462\t5.5244650673\t0.2285846895\t0.09226504396\n",
    "#     2.9332559936\t0.2218517503\t5.5227745727\t0.2292001046\t0.09218387021\n",
    "#     ])[:, mono_order]\n",
    "\n",
    "mono_runs = np.loadtxt(mono_file+'/MLE_'+PK_pop_model_file+'.csv')\n",
    "\n",
    "# mono_runs['K_cl mixed-effects'] = np.asarray([\n",
    "#     [0.6551785047, 1.3809146212, None, 0.1855965116, 0.1402454901],\n",
    "#     [0.7380118895, 1.5317061146, None, 0.1874982731, 0.1607835969]\n",
    "# ])[:, mono_order]\n",
    "\n",
    "# mono_runs['Fixed-effects'] = np.asarray([\n",
    "#     [1.3129154335, 2.1500067111, None, None, 0.7957449095],\n",
    "#     [1.3126919626, 2.1496641454, None, None, 0.795645034]\n",
    "# ])[:, mono_order]\n",
    "\n",
    "# conv_fail = [1]\n",
    "# fisher_fail = []\n",
    "mono_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import plotly.express.colors as pxclrs\n",
    "\n",
    "# powerset_params = chain.from_iterable(combinations(PK_params[:-1], r) for r in range(len(PK_params[:-1])+1))\n",
    "# colour_arg = np.flatnonzero([(x == tuple(model_mixed_params)) for x in powerset_params])[0]\n",
    "colour_arg = int(drug.split(\"_\")[2]) + 4*(len(data_mixed_params)-1) - 1\n",
    "model_colour = pxclrs.qualitative.Safe[colour_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "import plotly.graph_objects as go\n",
    "from scipy import interpolate\n",
    "\n",
    "plot = Plot_Models(\n",
    "    pop_model=population_model,\n",
    "    error_models=noise_model,\n",
    "    mech_model=PK_model,\n",
    "    data=df\n",
    ")\n",
    "plot.set_colour({\"base\":model_colour})\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "n_mix = len(model_mixed_params)*n_ids_data\n",
    "\n",
    "for param in PK_params:\n",
    "    pos = PK_pop_param_numbers[param]\n",
    "    shape_pos = PK_param_numbers[param]\n",
    "    param_value = ref_param[pos+n_mix]\n",
    "    if param in model_mixed_params:\n",
    "        omega_value = np.log(ref_param[pos+n_mix+1])\n",
    "        lower_bounds.append(param_value-shape_parameters[shape_pos])\n",
    "        lower_bounds.append(np.exp(omega_value-0.4))\n",
    "        upper_bounds.append(param_value+shape_parameters[shape_pos])\n",
    "        upper_bounds.append(np.exp(omega_value+0.4))\n",
    "    else:\n",
    "        param_value = np.log(param_value)\n",
    "        lower_bounds.append(np.exp(param_value-shape_parameters[shape_pos]))\n",
    "        upper_bounds.append(np.exp(param_value+shape_parameters[shape_pos]))\n",
    "\n",
    "names = pop_param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_bounds = (False, False)\n",
    "\n",
    "# Mixed V_c, K_cl:\n",
    "lower_bounds[1] = 1e-10  # 1: 1e-4  # 2: 1e-4  # 3: 1e-4  # 4: 1e-4\n",
    "force_bounds=(\n",
    "    [False, True, False, False, False],\n",
    "    [False, False, False, False, False]\n",
    ")\n",
    "\n",
    "# Mixed V_c:\n",
    "# lower_bounds[0] =  2.66  # 1: 2.775  # 2: 2.79  # 3: 2.78  # 4: 2.782  # 5: 2.66  # 6: 2.43  # 7: 2.35  # 8: 2.515\n",
    "# upper_bounds[0] =  2.76  # 1: 2.815  # 2: 2.825  # 3: 2.82  # 4: 2.817  # 5: 2.76  # 6: 2.56  # 7: 2.45  # 8: 2.575\n",
    "# lower_bounds[1] =  1.45  # 6: 1.45\n",
    "# upper_bounds[1] =  1.61  # 6: 1.61\n",
    "# # upper_bounds[2] =   # 3: 0.75  # 6: 0.85  # 8: 0.62\n",
    "# force_bounds=(\n",
    "#     [True, True, False, False],\n",
    "#     [True, True, False, False]\n",
    "# )\n",
    "\n",
    "# Mixed K_cl:\n",
    "# lower_bounds[2] =   # 1: 5.725  # 2: 5.9  # 3: 5.4  # 4: 5.6  # 5: 5.25  # 6: 5  # 7: 4.9  # 8: 5.1\n",
    "# lower_bounds[1] =   # 1: 0.06  # 2: 0.06  # 3: 0.08  # 4: 0.075\n",
    "# upper_bounds[2] =   # 1: 5.92  # 2: 6.1  # 3: 5.7  # 4: 5.9  # 5: 5.425  # 6: 5.275  # 7: 5.125  # 8: 5.4\n",
    "# force_bounds=(\n",
    "#     [False, False, True, False],\n",
    "#     [False, False, True, False]\n",
    "# )\n",
    "\n",
    "# Fixed:\n",
    "# lower_bounds[0] =   # 1: 2.82  # 2: 2.83  # 3: 2.85  # 4: 2.82  # 7: 2.775\n",
    "# upper_bounds[0] =   # 1: 2.91  # 2: 2.905  # 3: 2.945  # 4: 2.925  # 5: 3.1\n",
    "# upper_bounds[1] =   # 5: 6.65\n",
    "# force_bounds=(\n",
    "#     [False, False, False, False],\n",
    "#     [True, True, False, False]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_prior_function(ref_param):\n",
    "#     return log_prior(ref_param[-4:])\n",
    "\n",
    "fig = plot.plot_param_function(\n",
    "    log_likelihood, ref_param, profile=\"maximum\", pairwise=False,\n",
    "    individual_parameters=False, param_names=names, bounds=(lower_bounds, upper_bounds),\n",
    "    force_bounds=force_bounds, n_evals=100, profile_opts={\"method\":\"PINTS\"}\n",
    ")\n",
    "\n",
    "opt_score = log_likelihood(ref_param)\n",
    "\n",
    "min_x = [np.inf]*(len(ref_param)-n_mix)\n",
    "max_x = [-np.inf]*(len(ref_param)-n_mix)\n",
    "min_y = [np.inf]*(len(ref_param)-n_mix)\n",
    "max_y = [-np.inf]*(len(ref_param)-n_mix)\n",
    "interpolator = [None]*(len(ref_param)-n_mix)\n",
    "for trace_data in fig.data:\n",
    "    param_arg = trace_data.xaxis.split(\"x\")[-1]\n",
    "    if param_arg == \"\":\n",
    "        param_arg = 0\n",
    "    else:\n",
    "        param_arg = int(param_arg)-1\n",
    "    if len(trace_data.x)>2:\n",
    "        min_x[param_arg] = min(trace_data.x)\n",
    "        max_x[param_arg] = max(trace_data.x)\n",
    "        \n",
    "        min_y[param_arg] = min(trace_data.y)\n",
    "        max_y[param_arg] = max(trace_data.y)\n",
    "\n",
    "        interpolator[param_arg] = interpolate.interp1d(trace_data.x, trace_data.y)\n",
    "\n",
    "cmaes_runs = np.transpose(np.asarray(summary_df.iloc[:-1, :-2]))\n",
    "\n",
    "for cmaes_run, cmaes_inf_param in enumerate(cmaes_runs):\n",
    "    # if best[cmaes_run]:\n",
    "    #     continue\n",
    "\n",
    "    for param_arg, x in enumerate(cmaes_inf_param):\n",
    "        row = int(param_arg/3)+1\n",
    "        col = param_arg%3+1\n",
    "\n",
    "        if min_x[param_arg]<x<max_x[param_arg]:\n",
    "            cmaes_param_y = interpolator[param_arg](x)\n",
    "            if cmaes_param_y<-3.5:\n",
    "                cmaes_param_y = max_y[param_arg]\n",
    "        else:\n",
    "            cmaes_param_y = max_y[param_arg]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                name=\"Data-Set \"+str(colour_arg+1),\n",
    "                y=[min_y[param_arg], cmaes_param_y],\n",
    "                x=[x]*2,\n",
    "                mode='lines',\n",
    "                line=dict(color=model_colour, width=2),\n",
    "                showlegend=(param_arg == 0)&(cmaes_run == 0),\n",
    "                legendgroup=\"cmaes\",\n",
    "                legendgrouptitle_text=\"CMA-ES run result\"\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "    fig.update_yaxes(\n",
    "        range=[min_y, max_y],\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "\n",
    "for mono_run, mono_inf_param in enumerate(mono_runs):\n",
    "    for param_arg, x in enumerate(mono_inf_param):\n",
    "        if x is None:\n",
    "            continue\n",
    "        row = int(param_arg/3)+1\n",
    "        col = param_arg%3+1\n",
    "\n",
    "        param = list(PK_pop_param_numbers.keys())[param_arg]\n",
    "        if param in model_mixed_params:\n",
    "            x = np.log(x)\n",
    "        \n",
    "        if min_x[param_arg]<x<max_x[param_arg]:\n",
    "            mono_param_y = interpolator[param_arg](x)\n",
    "            if mono_param_y<-3.5:\n",
    "                mono_param_y = max_y[param_arg]\n",
    "        else:\n",
    "            mono_param_y = max_y[param_arg]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                name=\"Data-Set \"+str(colour_arg+1),\n",
    "                y=[min_y[param_arg], mono_param_y],\n",
    "                x=[x]*2,\n",
    "                mode='lines',\n",
    "                line=dict(color=model_colour, width=2, dash='dot'),\n",
    "                showlegend=(param_arg == 0)&(mono_run == 0),\n",
    "                legendgroup=\"mononlix\",\n",
    "                legendgrouptitle_text=\"Mononlix run result\"\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "\n",
    "fig.write_image(PK_image_file+'/'+PK_pop_model_file+\"_ll_profiles_compare.svg\")\n",
    "fig.show()\n",
    "\n",
    "# fig = plot.plot_param_function(\n",
    "#     log_likelihood, ref_param, profile=\"maximum\", pairwise=True,\n",
    "#     individual_parameters=False, param_names=names, bounds=(lower_bounds, upper_bounds),\n",
    "#     force_bounds=force_bounds, n_evals=50\n",
    "# )\n",
    "# fig.write_image(PK_image_file+\"/\"+PD_pop_model_file+fixed_file+\"_quick_ll_profiles_pair_from_True.svg\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(PK_image_file+'/'+PK_pop_model_file+\"_ll_profiles_data.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(fig.data, fp)  # encode dict into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "timer = pints.Timer()\n",
    "methods = ['L-BFGS-B', 'TNC', 'COBYLA']\n",
    "\n",
    "if model_mixed_params == [\"K_cl\"]:\n",
    "    param_interest = 2\n",
    "elif model_mixed_params == [\"V_c\"]:\n",
    "    param_interest = 0\n",
    "\n",
    "force_bounds_ind = [False, False]\n",
    "if type(force_bounds[0]) is not bool:\n",
    "    force_bounds_ind[0] = (force_bounds[0])[param_interest]\n",
    "else:\n",
    "    force_bounds_ind[0] = force_bounds[0]\n",
    "if type(force_bounds[1]) is not bool:\n",
    "    force_bounds_ind[1] = (force_bounds[1])[param_interest]\n",
    "else:\n",
    "    force_bounds_ind[1] = force_bounds[1]\n",
    "\n",
    "for method in methods:\n",
    "    print(method)\n",
    "    timer.reset()\n",
    "    fig = plot.plot_ind_profile_ll(\n",
    "        log_likelihood, param_interest, ref_param,\n",
    "        param_name=names[param_interest],\n",
    "        bounds=(lower_bounds[param_interest], upper_bounds[param_interest]),\n",
    "        force_bounds=force_bounds_ind, n_evals=100, method=method\n",
    "    )\n",
    "    fig.write_image(PK_image_file+'/'+PK_pop_model_file+\"_\"+method+\"_ll_profiles_\"+all_params[param_interest]+\"_ind_view.svg\")\n",
    "    fig.update_layout(width=300, height=750,)\n",
    "    fig.show()\n",
    "\n",
    "    time_str = timer.format(timer.time())\n",
    "    print(\"Time to complete graph:\", time_str)\n",
    "    result = [fig.data[0].x, fig.data[0].y]\n",
    "    try:\n",
    "        with open(PK_image_file+'/'+PK_pop_model_file+\"_ll_profiles_methods_trans_ind_data.pkl\", \"rb\") as fp:\n",
    "            pickle_data = pickle.load(fp)\n",
    "    except FileNotFoundError:\n",
    "        pickle_data = {}\n",
    "    \n",
    "    pickle_data[method] = {'Time': time_str, 'Result': result}\n",
    "    with open(PK_image_file+'/'+PK_pop_model_file+\"_ll_profiles_methods_trans_ind_data.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(pickle_data, fp)  # encode dict into pickle\n",
    "print(\"Time to complete graph:\", time_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further adjustables\n",
    "max_runs = 5\n",
    "method_name = \"NUTS\"\n",
    "\n",
    "if method_name == \"NUTS\":\n",
    "    num_samples = 3000  # number of wanted final samples\n",
    "    method = pints.NoUTurnMCMC\n",
    "elif method_name == \"HBMC\":\n",
    "    num_samples = 60000\n",
    "    method = pints.HaarioBardenetACMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Inference import SamplingController\n",
    "\n",
    "log_posterior = problem.get_log_posterior()\n",
    "sampler = SamplingController(log_posterior)\n",
    "# sampler.set_n_runs(max_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_pop_params = pandas.read_csv(PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_pop.csv\")\n",
    "inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "opt_ind_params = np.load(PK_data_file+drug+'/'+PK_pop_model_file+\"_opt_ind.npy\")\n",
    "\n",
    "log_posterior_values = inferred_pop_params.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "log_posterior_values = np.asarray(log_posterior_values)\n",
    "\n",
    "converged = log_posterior_values >= (np.max(log_posterior_values)+np.log(0.02))\n",
    "n_runs = np.count_nonzero(converged)\n",
    "\n",
    "if n_runs < 3:\n",
    "    print(\n",
    "        \"Not enough consistent results from the Maximum\"+\n",
    "        \"Likelihood Estimation to start Sampling\"\n",
    "    )\n",
    "else:\n",
    "    if n_runs > max_runs:\n",
    "        n_runs = max_runs\n",
    "    sampler.set_n_runs(n_runs)\n",
    "    opt_params = (\n",
    "        inferred_pop_params.drop(columns=['Mean', 'True']).values[:, converged]\n",
    "    )[:-1, :n_runs]\n",
    "    ind_params = (opt_ind_params[converged])[:n_runs]\n",
    "    sampler.set_initial_point(\n",
    "        range(1, n_runs+1), opt_params.transpose(), ind_params\n",
    "    )\n",
    "    for i, param in enumerate(population_model.get_parameter_names()):\n",
    "        print(param, opt_params[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_length = int(num_samples/n_runs)+100\n",
    "print(\"running samplers for \"+str(run_length)+\" iterations\")\n",
    "cov_0 = None\n",
    "sampler.set_sampler(method)\n",
    "sampler.set_stop_criterion(\n",
    "    max_iterations=run_length\n",
    ")\n",
    "sampler.set_transform(transformation)\n",
    "posterior_samples = sampler.run(\n",
    "    n_iterations=run_length,\n",
    "    log_to_screen=True\n",
    ")\n",
    "posterior_samples.to_netcdf(PK_data_file+drug+\"/\"+PK_pop_model_file+\"_\"+method_name+\"_samples.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "posterior_samples = xr.open_dataset(PK_data_file+drug+\"/\"+PK_pop_model_file+\"_\"+method_name+\"_samples.nc\").load()\n",
    "posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "lines = list(zip(*(population_model.get_parameter_names(),[{}]*len(PK_true_pops), PK_true_pops)))\n",
    "\n",
    "# Discard warmup iterations\n",
    "discard = 100 # max(len(posterior_samples.draw)-int(num_samples/n_runs), 1)\n",
    "main_samples = posterior_samples.drop_isel(draw=range(0, discard))\n",
    "\n",
    "print(\"R-hat value:\", az.rhat(main_samples))\n",
    "\n",
    "plot_names = pop_param_names.copy()\n",
    "for param in model_mixed_params:\n",
    "    if param in PK_param_numbers:\n",
    "        pos = PK_param_numbers[param]\n",
    "        ind_param_name = \"Individual \" + PK_param_names[pos]\n",
    "        plot_names = np.concatenate((plot_names, [ind_param_name]))\n",
    "\n",
    "plot = Plot_Models(population_model, noise_model, PK_model, log_prior, df)\n",
    "fig = plot.plot_param_sampling(main_samples, lines=lines, param_names=plot_names, legend=True)\n",
    "fig.savefig(PK_image_file+'/'+PK_pop_model_file+\"_\"+method_name+\"_Pop_trace_plot.svg\")\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Model assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PK_image_file = \"../Images/PK_sim/PK_comp\"+str(num_PK_comp)+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import figure_factory as ff\n",
    "\n",
    "number_of_converged = [  # All, V_C, K_cl, None\n",
    "    [\"1 (1 M-E param)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "    [\"2 (1 M-E param)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "    [\"3 (1 M-E param)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "    [\"4 (1 M-E param)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "    [\"5 (2 M-E params)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "    [\"6 (2 M-E params)\",\"10\", \"6, 3, 1\", \"10\", \"10\"],\n",
    "    [\"7 (2 M-E params)\",\"10\", \"1, 8, 1\", \"10\", \"10\"],\n",
    "    [\"8 (2 M-E params)\",\"10\", \"10\", \"10\", \"10\"],\n",
    "]\n",
    "\n",
    "table_df = pandas.DataFrame(data=number_of_converged, columns=[\"Dataset\", \"All params M-E\", \"V_c M-E\", \"K_{cl} M-E\", \"F-E\"])\n",
    "# table_df = table_df.set_index(\"Dataset\", )\n",
    "\n",
    "fig = ff.create_table(table_df)\n",
    "fig.update_layout(\n",
    "    width=550,\n",
    "    height=200\n",
    ")\n",
    "fig.write_image(PK_image_file+\"converged_comparison.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy import interpolate\n",
    "\n",
    "fig_range = [-4, 0.02]\n",
    "\n",
    "print(\"Mixed-effects:\", model_mixed_params)\n",
    "fig_data = []\n",
    "for data_set in range(0, 4):\n",
    "    dataset_file_name = \"large_data_\"+str(data_set+1)+\"_1pop\"\n",
    "    with open(PK_image_file+dataset_file_name+'/'+PK_pop_model_file +\"_ll_profiles_data.pkl\", 'rb') as fp:\n",
    "        fig_data += pickle.load(fp)\n",
    "\n",
    "for data_set in range(0, 4):\n",
    "    dataset_file_name = \"large_data_\"+str(data_set+1)+\"_2pop\"\n",
    "    with open(PK_image_file+dataset_file_name+'/'+PK_pop_model_file +\"_ll_profiles_data.pkl\", 'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "        for trace_data in data:\n",
    "            if trace_data.xaxis == 'x':\n",
    "                param_num = 1\n",
    "            else:\n",
    "                param_num = int(trace_data.xaxis[-1])\n",
    "            trace_data.yaxis ='y' + str(len(pop_param_names)+param_num)\n",
    "            trace_data.xaxis ='x' + str(len(pop_param_names)+param_num)\n",
    "\n",
    "        fig_data += data\n",
    "\n",
    "max_y = -np.inf\n",
    "mix_nums = np.array([])\n",
    "min_x = np.ones(len(pop_param_names)*2)*(np.infty)\n",
    "max_x = np.ones(len(pop_param_names)*2)*(-np.infty)\n",
    "mins = [[]]*5\n",
    "maxs = [[]]*5\n",
    "for trace_data in fig_data:\n",
    "    if trace_data.xaxis == 'x':\n",
    "        i_axis = 1\n",
    "    else:\n",
    "        i_axis = int(trace_data.xaxis[-1])\n",
    "    \n",
    "    if i_axis>len(pop_param_names):\n",
    "        param_num = i_axis-len(pop_param_names)-1\n",
    "    else:\n",
    "        param_num = i_axis-1\n",
    "    \n",
    "    if (param_num not in (mix_nums+1)) and (param_num != len(pop_param_names)-1):\n",
    "        n_mix = np.count_nonzero(mix_nums<param_num)\n",
    "        param = PK_params[param_num-n_mix]\n",
    "        if param in model_mixed_params:\n",
    "            trace_data.x = np.exp(trace_data.x)\n",
    "            mix_nums = np.union1d(mix_nums, [param_num])\n",
    "\n",
    "    if len(trace_data.x)>2:\n",
    "        optima_arg = np.argmax(trace_data.y)\n",
    "        max_y = max(trace_data.y[optima_arg], max_y)\n",
    "\n",
    "        if trace_data.x[0]<fig_range[0]:\n",
    "            interpolator = interpolate.interp1d(\n",
    "                trace_data.y[:optima_arg],\n",
    "                trace_data.x[:optima_arg]\n",
    "            )\n",
    "            x_at_min = interpolator(fig_range[0])\n",
    "        else:\n",
    "            x_at_min = trace_data.x[0]\n",
    "        \n",
    "        if trace_data.x[-1]<fig_range[0]:\n",
    "            interpolator = interpolate.interp1d(\n",
    "                trace_data.y[len(trace_data.y):optima_arg:-1],\n",
    "                trace_data.x[len(trace_data.y):optima_arg:-1]\n",
    "            )\n",
    "            x_at_max = interpolator(fig_range[0])\n",
    "        else:\n",
    "            x_at_max = trace_data.x[-1]\n",
    "        \n",
    "        min_x[i_axis-1] = min(x_at_min, min_x[i_axis-1])\n",
    "        max_x[i_axis-1] = max(x_at_max, max_x[i_axis-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "share_xaxes = True\n",
    "\n",
    "n_cols = len(pop_param_names)\n",
    "n_rows = 2\n",
    "\n",
    "fig = go.Figure(data=fig_data).set_subplots(\n",
    "    n_rows, n_cols, \n",
    "    shared_xaxes=share_xaxes, shared_yaxes=True,\n",
    "    subplot_titles=pop_param_names\n",
    ")\n",
    "for col in range(1, len(pop_param_names)+1):\n",
    "    for row in range(1, 3):\n",
    "        i_axis = (row-1)*len(pop_param_names) + col\n",
    "\n",
    "        if share_xaxes:\n",
    "            CI_x = [\n",
    "                min(min_x[col-1], min_x[col+len(pop_param_names)-1]),\n",
    "                max(max_x[col-1], max_x[col+len(pop_param_names)-1])\n",
    "            ]\n",
    "        else:\n",
    "            CI_x = [min_x[i_axis-1], max_x[i_axis-1]]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                name=\"Confidence Interval\",\n",
    "                y=[-1.98]*2,\n",
    "                x=CI_x,\n",
    "                mode='lines',\n",
    "                line=dict(color=\"Black\", width=2, dash='dash'),\n",
    "                showlegend=(i_axis == 1)\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        true_param = PK_true_pops[col-1]\n",
    "        if CI_x[0]<true_param<CI_x[1]:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    name=\"Data-generating parameter\",\n",
    "                    y=fig_range,\n",
    "                    x=[true_param]*2,\n",
    "                    mode='lines',\n",
    "                    line=dict(color=\"black\", width=2),\n",
    "                    showlegend=(i_axis == 1),\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "\n",
    "fig.update_yaxes(\n",
    "    range=fig_range,\n",
    "    title_text='Log-Likelihood Score'\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Parameter Value\")\n",
    "\n",
    "if len(model_mixed_params)==0:\n",
    "    title = \"Fixed effects model\"\n",
    "else:\n",
    "    title = \"Mixed-effects: \"+ \", \".join(model_mixed_params)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=title,\n",
    "    width=500+300*n_cols,\n",
    "    height=250+200*n_rows,\n",
    ")\n",
    "\n",
    "if share_xaxes:\n",
    "    fig.write_image(PK_image_file+ '/' + PK_pop_model_file + \"_ll_comparison.svg\")\n",
    "else:\n",
    "    fig.write_image(PK_image_file+ '/' + PK_pop_model_file + \"_ll_comparison_sepx.svg\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PD Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in the data simulated from the Naive model\n",
    "# df = pandas.read_csv(\"../Data_and_parameters/PK_sim/sythesised_data_real_timepoints.csv\")\n",
    "# df = df.sort_values(['ID', 'TIME'], ascending=True, ignore_index=True)\n",
    "# dose_unit = \"mg\"\n",
    "\n",
    "# # Reformat this into Something Chi understands\n",
    "# df = df.rename(columns={'TIME':'Time', 'OBS': 'Value', 'DOSE':'Dose group'})\n",
    "# df['Observable'] = ['central.drug_concentration']*len(df)\n",
    "# dosing_df = df.groupby('ID',as_index=False)['Dose group'].mean()\n",
    "# dosing_df.columns = ['ID', 'Dose']\n",
    "# dosing_df['Time'] = [0.0]*len(dosing_df)\n",
    "# dosing_df['Duration'] = [0.001]*len(dosing_df)\n",
    "\n",
    "# df = pandas.concat([df, dosing_df], join='outer', ignore_index=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data-generating parameters\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "PK_true_typs = np.load(PK_data_file+\"actual_params.npy\")\n",
    "# PK_actual_pop_params = np.load(PK_data_file+\"actual_pop_params.npy\")\n",
    "# print(\"PK_actual_pop_params\", PK_actual_pop_params)\n",
    "PD_actual_params = np.load(PD_data_file+\"actual_params.npy\")\n",
    "\n",
    "# Define population parameters\n",
    "PK_true_omegas = [1e-10, 1e-10, 0.3] + [1e-10]*8\n",
    "order = [5, 0, 1, 2, 3, 6, 7, 8,  4, 9]\n",
    "np.save(PD_data_file+\"omega.npy\", PK_true_omegas)\n",
    "PKPD_real_params = np.concatenate((PK_true_typs, PD_actual_params), axis=1)[:, order]\n",
    "split_param_names = np.char.split(PKPD_real_params[0, :], \", \")\n",
    "PKPD_real_pop_params = PKPD_real_params\n",
    "for x in model_mixed_params.values():\n",
    "    pos = x+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<x)\n",
    "    PKPD_real_pop_params = np.insert(\n",
    "        PKPD_real_pop_params,\n",
    "        pos+1,\n",
    "        [\"omega_\"+split_param_names[x][0] , PK_true_omegas[x]],\n",
    "        axis=1\n",
    "    )\n",
    "    PKPD_real_pop_params[0, pos] = str().join([split_param_names[x][0], \"_typ\", \", \"]+list(split_param_names[x][1:]))\n",
    "PKPD_real_pop_params = np.insert(\n",
    "    PKPD_real_pop_params,\n",
    "    [6+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<=6)],\n",
    "    [['Nonsense'] , [0]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "PK_bounds = np.load(\"../Data_and_parameters/PK_sim/bounds.npy\")\n",
    "PD_bounds = np.load(\"../Data_and_parameters/PD_sim/bounds.npy\")\n",
    "PKPD_bounds = np.concatenate((PK_bounds , PD_bounds ), axis=1)[:, order]\n",
    "\n",
    "\n",
    "table_df = pandas.DataFrame(PKPD_real_pop_params.transpose(), columns=['Parameter name', 'Data generating value'])\n",
    "table_df = table_df.astype({'Data generating value':float})\n",
    "table_df = table_df.round({'Data generating value':4})\n",
    "table_df = table_df.set_index('Parameter name').transpose()\n",
    "\n",
    "fig =  ff.create_table(table_df)\n",
    "fig.update_layout(\n",
    "    width=700,\n",
    "    height=45,\n",
    ")\n",
    "# fig.write_image(PD_image_file+\"/data_table.svg\")\n",
    "\n",
    "pop_param_names = PKPD_real_pop_params[0, :]\n",
    "PKPD_real_pop_params = PKPD_real_pop_params[1, :].astype('float64')\n",
    "\n",
    "PK_param_names = PK_true_typs[0, :]\n",
    "PD_param_names = PD_actual_params[0, :]\n",
    "\n",
    "PK_true_typs = PK_true_typs[1, :].astype('float64')\n",
    "PD_actual_params = PD_actual_params[1, :].astype('float64')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.PD_model import ChiMyelotoxicityPKPD\n",
    "from Code.PK_model import ChiPKLin\n",
    "import chi\n",
    "import logging\n",
    "\n",
    "# Remove Annoying logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Set up the model\n",
    "PK_model = ChiPKLin(num_comp=num_PK_comp)\n",
    "PKPD_model = ChiMyelotoxicityPKPD(PK_model, 'central.drug_concentration')\n",
    "\n",
    "PKPD_model.set_administration(\n",
    "    compartment='PK_central', amount_var='drug_amount')\n",
    "\n",
    "PKPD_model.set_outputs(['PK_central.drug_concentration', 'circulating.R'])\n",
    "\n",
    "PK_noise_model = chi.MultiplicativeGaussianErrorModel()\n",
    "PD_noise_model = chi.GaussianErrorModel()\n",
    "\n",
    "PK_opt_params = pandas.read_csv(PK_data_file+drug+\"/\"+PK_pop_model_file+\"_opt_pop.csv\")\n",
    "PK_opt_params = PK_opt_params.set_index(\"Parameter\")\n",
    "log_posterior_values = PK_opt_params.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "log_posterior_values = np.asarray(log_posterior_values)\n",
    "converged = log_posterior_values>=(np.max(log_posterior_values)+np.log(0.02))\n",
    "n_conv = np.count_nonzero(converged)\n",
    "\n",
    "if n_conv<3:\n",
    "    print(\"Not enough consistent results from the PK Maximum Likelihood Estimation to start PD\")\n",
    "else:\n",
    "    PK_opt_params = (PK_opt_params.drop(columns=['Mean', 'True']).values[:, converged])[:-1]\n",
    "    PK_opt_params = PK_opt_params.mean(axis=1)\n",
    "print(PK_opt_params)\n",
    "\n",
    "fixed = {}\n",
    "pop_models = []\n",
    "for param in all_params:\n",
    "    if param == \"Nonsense\":\n",
    "        fixed[\"drug.drug_concentration\"]= 0\n",
    "    elif param in model_fixed_params:\n",
    "        print(param, \"fixed\")\n",
    "        if param == \"sigma_PK\":\n",
    "            fixed[\"PK_central.drug_concentration Sigma rel.\"] = PK_opt_params[-1]\n",
    "        else:\n",
    "            mix_arr = np.asarray(list(model_mixed_params.values()))\n",
    "            pos = model_fixed_params[param][0] + np.count_nonzero(\n",
    "                (0 < mix_arr) &\n",
    "                (mix_arr < model_fixed_params[param][1])\n",
    "            )\n",
    "            fixed['PK_'+PK_model.parameters()[model_fixed_params[param][0]]] = PK_opt_params[pos]\n",
    "    elif param in model_mixed_params:\n",
    "        print(param, \"mixed\")\n",
    "        pop_models.append(chi.LogNormalModel(n_dim=1))\n",
    "    elif param in model_no_pooled_params:\n",
    "        print(param, \"no pooled\")\n",
    "        pop_models.append(chi.HeterogeneousModel(n_dim=1))\n",
    "    else:\n",
    "        print(param, \"pooled\")\n",
    "        pop_models.append(chi.PooledModel(n_dim=1))\n",
    "\n",
    "population_model = chi.ComposedPopulationModel(pop_models)\n",
    "\n",
    "# Set up the inference problem\n",
    "problem = chi.ProblemModellingController(PKPD_model, [PK_noise_model, PD_noise_model])\n",
    "problem.fix_parameters(fixed)\n",
    "problem.set_population_model(population_model)\n",
    "\n",
    "# # Set the bounds on the parameters and start point\n",
    "# # lower_bound = [0.01, 0.1*V_c_approx, 0.01, 0.01*V_c_approx, 0.0001]\n",
    "# # upper_bound = [100, 10*V_c_approx, 100, 100*V_c_approx, 1]\n",
    "\n",
    "# # np.save(\"../Data_and_parameters/PK_sim/bounds\", np.asarray([lower_bound, upper_bound]))\n",
    "# PK_bounds = np.load(\"../Data_and_parameters/PK_sim/bounds.npy\")\n",
    "# PD_bounds = np.load(\"../Data_and_parameters/PD_sim/bounds.npy\")\n",
    "\n",
    "# # PD_bounds[0] = 1.2*PD_bounds[0]\n",
    "# # PD_bounds[1] = 0.6*PD_bounds[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fixed)\n",
    "population_model.get_parameter_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulated data\n",
    "dose_amts = [1.0, 2.0, 3.0]\n",
    "n_ids_data = 15*len(dose_amts)\n",
    "dose_time = 48\n",
    "n_times_data = 50\n",
    "\n",
    "# PK_times = np.linspace(0.05, 5, n_times_data)[:] + dose_time\n",
    "# PD_times = np.linspace(-dose_time, 500, n_times_data)[:] + dose_time\n",
    "# data = pandas.DataFrame(columns=[\"ID\", \"Time\", \"Observable\", \"Value\", \"Dose group\", \"Duration\", \"Dose\"])\n",
    "\n",
    "# # Acquire patient parameters\n",
    "# reduced_pop_params = PKPD_actual_pop_params.copy()\n",
    "# reduced_pop_params[list(model_mixed_params.values())] = np.log(reduced_pop_params[list(model_mixed_params.values())])\n",
    "# reduced_pop_params = np.delete(\n",
    "#     reduced_pop_params,\n",
    "#     [x[1]+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<x[1]) \n",
    "#      for x in model_fixed_params.values()]\n",
    "# )\n",
    "# individual_parameters = population_model.sample(\n",
    "#     parameters=reduced_pop_params,\n",
    "#     n_samples=n_ids_data\n",
    "# )\n",
    "# # for i, var in enumerate(PKPD_model._const_names):\n",
    "# #     print(var, individual_parameters[0, i])\n",
    "\n",
    "# patient = 0\n",
    "# for i, dose in enumerate(dose_amts):\n",
    "#     # Set administration and dosing regimen\n",
    "#     PKPD_model.set_dosing_regimen(dose=dose, start=dose_time, period=0)\n",
    "#     for _ in range(0, int(n_ids_data/len(dose_amts))):\n",
    "#         # Simulate model\n",
    "#         param = np.insert(individual_parameters[patient, :], 6, 0)\n",
    "#         patient_result = PKPD_model.simulate(param[:-2], np.concatenate((PK_times, PD_times[5:])))\n",
    "        \n",
    "#         # produce data\n",
    "#         include_PK_data = dose!=0.0\n",
    "\n",
    "#         patient_data = pandas.DataFrame()\n",
    "#         patient_data_length = len(PK_times)*include_PK_data+len(PD_times)+1\n",
    "#         patient_data[\"ID\"] = [patient+1]*patient_data_length\n",
    "#         if include_PK_data:\n",
    "#             patient_data[\"Time\"] = np.concatenate((PK_times, PD_times, [dose_time]))\n",
    "#             patient_data[\"Observable\"] = (\n",
    "#                 ['PK_central.drug_concentration']*len(PK_times)+['circulating.R']*len(PD_times)+[None]\n",
    "#             )\n",
    "#             PK_result = PK_noise_model.sample(param[-2:-1], patient_result[0, :len(PK_times)])[:, 0]\n",
    "#         else:\n",
    "#             patient_data[\"Time\"] = np.concatenate((PD_times, [dose_time]))\n",
    "#             patient_data[\"Observable\"] = (\n",
    "#                 ['circulating.R']*len(PD_times)+[None]\n",
    "#             )\n",
    "#             PK_result = []\n",
    "\n",
    "#         PD_result = PD_noise_model.sample(\n",
    "#             param[-1:],\n",
    "#             np.concatenate(([param[5]]*5, patient_result[1, len(PK_times):]))\n",
    "#         )[:, 0]\n",
    "#         patient_data[\"Value\"] = np.concatenate((PK_result, PD_result, [None]))\n",
    "\n",
    "#         patient_data[\"Dose group\"] = [dose]*patient_data_length\n",
    "#         patient_data[\"Duration\"] = [None]*(patient_data_length-1)+[0.01]\n",
    "#         patient_data[\"Dose\"] = [None]*(patient_data_length-1)+[dose]\n",
    "#         data = pandas.concat([data, patient_data])\n",
    "#         patient += 1\n",
    "\n",
    "# data.to_csv(PD_data_file + drug+\"/data.csv\", index=False)\n",
    "# np.save(PD_data_file + drug+\"/ind_Vc_param.npy\", individual_parameters[:, 2])\n",
    "\n",
    "df = pandas.read_csv(PD_data_file + drug+\"/data.csv\")\n",
    "n_ids_data = len(df[\"ID\"].unique())\n",
    "\n",
    "ind_real_params = np.asarray([PKPD_real_pop_params]*n_ids_data)\n",
    "ind_real_params[:, 2] = np.load(PD_data_file + drug+\"/ind_Vc_param.npy\")\n",
    "dose_unit = \"mg\"\n",
    "\n",
    "problem.set_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# First estimate the parameter V_c. We can do this by drawing a line through the first 2 points and seeing where it crosses the y-axis\n",
    "df_obs = df.loc[df['Observable']=='PK_central.drug_concentration']\n",
    "PK_data = df.loc[df['ID'].isin(df_obs['ID'].unique())]\n",
    "df_dose = np.asarray(PK_data.groupby('ID')['Dose'].first())\n",
    "df_obs['rank'] = df_obs.sort_values('Time').groupby('ID').cumcount()+1\n",
    "points_1st = df_obs[df_obs['rank'] == 1].sort_values('ID', ignore_index=True)\n",
    "points_2nd = df_obs[df_obs['rank'] == 2].sort_values('ID', ignore_index=True)\n",
    "\n",
    "y_0 = points_1st['Value'] - (points_1st['Time']-dose_time) * (\n",
    "    (points_1st['Value'] - points_2nd['Value'])\n",
    "    / ((points_1st['Time']-dose_time)- (points_2nd['Time']-dose_time))\n",
    ")\n",
    "V_c_approx = (df_dose/y_0).mean()\n",
    "\n",
    "AUC_0_last = np.empty(len(PK_data[\"ID\"].unique()))\n",
    "C_last = np.empty(len(PK_data[\"ID\"].unique()))\n",
    "lambda_z = np.empty(len(PK_data[\"ID\"].unique()))\n",
    "for i, patient in enumerate(PK_data[\"ID\"].unique()):\n",
    "    y_ind = np.asarray(df_obs.loc[df_obs['ID']==patient]['Value'])\n",
    "    x_ind = np.asarray(df_obs.loc[df_obs['ID']==patient]['Time'])-dose_time\n",
    "    AUC_0_last[i] = simpson(y=y_ind, x=x_ind)\n",
    "    C_last[i] = y_ind[-1]\n",
    "    lambda_z[i] = linregress(x=x_ind[int(0.5*len(x_ind)):], y=x_ind[int(0.5*len(x_ind)):]).slope\n",
    "AUC_inf = AUC_0_last+C_last/lambda_z\n",
    "cl_approx = (df_dose/AUC_inf).mean()\n",
    "\n",
    "df_R_before_dose = df[(df[\"Time\"] < dose_time) & (df[\"Observable\"]=='circulating.R')]\n",
    "R_0_approx = np.mean(df_R_before_dose[\"Value\"])\n",
    "\n",
    "nadir = np.empty((2, len(PK_data[\"ID\"].unique())))\n",
    "for i, patient in enumerate(df[\"ID\"].unique()):\n",
    "    df_PD_ind = df[(df[\"ID\"]==patient) & (df[\"Observable\"]=='circulating.R')]\n",
    "    df_nadir = df_PD_ind[df_PD_ind.Value == df_PD_ind.Value.min()]\n",
    "    y_nadir = df_nadir.Value.iat[0]\n",
    "    t_nadir = df_nadir.Time.iat[0]-dose_time\n",
    "    nadir[:, i] = (t_nadir, y_nadir)\n",
    "\n",
    "MTT_approx = 0.5*nadir[0,:].mean()\n",
    "S_approx = np.mean((1-(nadir[1,:] - R_0_approx)/(nadir[0,:])*MTT_approx/4)*(V_c_approx/df_dose))\n",
    "\n",
    "Approximations = [\n",
    "    S_approx,           # S\n",
    "    cl_approx,          # Clearance\n",
    "    V_c_approx,         # Central volume\n",
    "    cl_approx,          # Periferal compartment transfer\n",
    "    V_c_approx,         # Periferal compartment volume\n",
    "    R_0_approx,         # R_0\n",
    "    0,                  # Nonsense\n",
    "    0.5,                # gamma\n",
    "    MTT_approx,         # MTT\n",
    "    0.1,                # PK Noise parameter\n",
    "    0.1*R_0_approx,     # PD Noise parameter\n",
    "]\n",
    "\n",
    "if len(model_mixed_params) == 0:\n",
    "    table_df.loc[\"Approximate\"] = np.asarray(Approximations).round(4)\n",
    "else:\n",
    "    table_df.loc[\"Approximate\"] = np.insert(\n",
    "        Approximations,\n",
    "        np.asarray(list(model_mixed_params.values()))+1,\n",
    "        [np.nan]*len(model_mixed_params)\n",
    "    ).round(4)\n",
    "\n",
    "shape_parameters = [\n",
    "    0.5,                        # S\n",
    "    0.75,                       # Clearance\n",
    "    0.4,                        # Central volume\n",
    "    3,                          # Periferal compartment transfer\n",
    "    0.8,                        # Periferal compartment volume\n",
    "    0.5,                        # R_0\n",
    "    np.NaN,                     # Nonsense\n",
    "    1.2,                        # gamma\n",
    "    0.5,                        # MTT\n",
    "    0.4,                        # PK Noise parameter\n",
    "    2.1,                        # PD Noise parameter\n",
    "]\n",
    "\n",
    "fig =  ff.create_table(table_df, index=True)\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=65\n",
    ")\n",
    "# fig.write_image(PD_image_file+\"/data_table.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pints\n",
    "\n",
    "log_priors = []\n",
    "transformations = []\n",
    "for param in all_params:\n",
    "    if param in model_mixed_params:\n",
    "        log_priors.append(pints.GaussianLogPrior(np.log(Approximations[PKPD_param_numbers[param]]), shape_parameters[PKPD_param_numbers[param]]))\n",
    "        log_priors.append(pints.LogNormalLogPrior(np.log(shape_parameters[PKPD_param_numbers[param]]), 0.4))\n",
    "        transformations = [pints.LogTransformation(n_ids_data)] +  transformations\n",
    "        transformations.append(pints.IdentityTransformation(2))\n",
    "    elif param not in model_fixed_params:\n",
    "        log_priors.append(pints.LogNormalLogPrior(np.log(Approximations[PKPD_param_numbers[param]]), shape_parameters[PKPD_param_numbers[param]]))\n",
    "        transformations.append(pints.LogTransformation(1))\n",
    "        \n",
    "\n",
    "# log_priors = [\n",
    "#     pints.UniformLogPrior(PD_bounds[0,0], PD_bounds[1,0]),                  # S\n",
    "#     pints.LogNormalLogPrior(np.log(cl_approx), 0.75),                       # Clearance\n",
    "#     pints.GaussianLogPrior(np.log(V_c_approx), 0.4),                        # Log mean of central volume\n",
    "#     pints.LogNormalLogPrior(-1, 0.4),                                       # Log std. of central volume\n",
    "#     pints.LogNormalLogPrior(np.log(cl_approx), 3),                          # Periferal compartment transfer\n",
    "#     pints.LogNormalLogPrior(np.log(V_c_approx), 0.8),                       # Periferal compartment volume\n",
    "#     pints.LogNormalLogPrior(np.log(R_0_approx), 0.5),                       # R_0\n",
    "#     pints.LogNormalLogPrior(np.log(0.5), np.sqrt(-np.log(0.25))),           # gamma\n",
    "#     pints.LogNormalLogPrior(np.log(MTT_approx), 0.5),                       # MTT\n",
    "#     pints.LogNormalLogPrior(-1, 0.4),                                       # PK Noise parameter\n",
    "#     pints.LogNormalLogPrior(np.log(0.1*R_0_approx), np.sqrt(-np.log(0.01))),# PD Noise parameter\n",
    "# ]\n",
    "# log_priors = \n",
    "\n",
    "log_prior = pints.ComposedLogPrior(*log_priors)\n",
    "\n",
    "# Transform Parameter Space\n",
    "transformation = pints.ComposedTransformation(*transformations)\n",
    "#     pints.LogTransformation(len(df['ID'].unique())+2), # Individual parameters, S, Clearance\n",
    "#     pints.IdentityTransformation(1),                   # Log mean of central volume\n",
    "#     pints.IdentityTransformation(1),                   # Log std. of central volume\n",
    "#     pints.LogTransformation(4),                        # Periferal compartment, R_0, gamma, MTT, PK Noise parameter, PD Noise parameter\n",
    "# )\n",
    "problem.set_log_prior(log_prior)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- import numpy as np\n",
    "import pints\n",
    "import chi\n",
    "from Code.PK_model import ChiPKLin\n",
    "import logging\n",
    "\n",
    "# Remove Annoying logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Define parameters\n",
    "PK_params = np.load(\"../Data_and_parameters/PK_sim/actual_params.npy\")\n",
    "PK_params = PK_params[:, [1,0,3,2, -1]]\n",
    "PK_param_names = PK_params[0, :]\n",
    "PK_params = PK_params[1, :].astype('float64')\n",
    "\n",
    "# Define population parameters\n",
    "population_parameters = np.concatenate(([PK_params[0], np.log(PK_params[1]), 0.3], PK_params[2:]))\n",
    "\n",
    "# Define pharmacokinetic model\n",
    "mechanistic_model = ChiPKLin(num_comp=2)\n",
    "mechanistic_model.set_administration(\n",
    "    compartment='central', amount_var='drug_amount')\n",
    "error_model = chi.MultiplicativeGaussianErrorModel()\n",
    "\n",
    "# Define population model\n",
    "\n",
    "# pop_theta_names = PK_param_names[1].split(\",\")\n",
    "# pop_typ_name = pop_theta_names[0]+\"_typ,\"+pop_theta_names[1]\n",
    "# pop_omega_name = \"omega_\"+pop_theta_names[0]\n",
    "\n",
    "population_model = chi.ComposedPopulationModel([\n",
    "    chi.PooledModel(n_dim=1, dim_names=[PK_param_names[0]]),\n",
    "    chi.LogNormalModel(\n",
    "        n_dim=1, dim_names=[PK_param_names[1]]\n",
    "    ),\n",
    "    chi.PooledModel(n_dim=3, dim_names=list(PK_param_names[2:]))])\n",
    "pop_predictive_model = chi.PopulationPredictiveModel(\n",
    "    chi.PredictiveModel(mechanistic_model, error_model), population_model)\n",
    "\n",
    "# Get individual parameters\n",
    "dose_amts = [1, 2, 4]\n",
    "n_ids = 12 * len(dose_amts)\n",
    "individual_parameters = population_model.sample(\n",
    "    parameters=population_parameters,\n",
    "    n_samples=n_ids,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "times = np.arange(0.1, 5.1, 0.5)\n",
    "data = pandas.DataFrame(columns=[\"ID\", \"Time\", \"Observable\", \"Value\", \"Duration\", \"Dose\"])\n",
    "\n",
    "for i, dose in enumerate(dose_amts):\n",
    "    # Set administration and dosing regimen\n",
    "    pop_predictive_model.set_dosing_regimen(dose=dose, period=0)\n",
    "    patient_data = pop_predictive_model.sample(\n",
    "        population_parameters, times, include_regimen=True, n_samples=12)\n",
    "    patient_data[\"ID\"] = patient_data[\"ID\"] + 12*i\n",
    "    data = pandas.concat([data, patient_data])\n",
    "\n",
    "problem = chi.ProblemModellingController(mechanistic_model, error_model)\n",
    "problem.set_population_model(population_model)\n",
    "problem.set_data(data)\n",
    "data -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "\n",
    "ind_param_map = {}\n",
    "pop_parameters = PKPD_real_pop_params.copy()\n",
    "adj = 0\n",
    "for param, pos in PKPD_param_numbers.items():\n",
    "    if param in model_mixed_params:\n",
    "        ind_param_map[PKPD_model.parameters()[pos]] = ind_real_params[:, pos]\n",
    "        pop_parameters[pos+adj] = np.log(pop_parameters[pos+adj])\n",
    "        adj += 1\n",
    "    elif param in model_fixed_params:\n",
    "        pop_parameters = np.delete(pop_parameters, pos+adj)\n",
    "        adj -= 1\n",
    "\n",
    "plot = Plot_Models(population_model, mech_model=PKPD_model, prior_model=log_prior)\n",
    "plot.set_data(df)\n",
    "fig = plot.plot_pop_distribution(\n",
    "    pop_parameters, ind_param_map\n",
    ")\n",
    "fig.write_image(\n",
    "    PD_image_file+\"/\"\n",
    "    +PD_pop_model_file + fixed_file + \"_pop_dist.svg\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = []\n",
    "upper = []\n",
    "param_names = []\n",
    "i_mix = 0\n",
    "i_non = 0\n",
    "for param, pos in PKPD_param_numbers.items():\n",
    "    if param in model_mixed_params:\n",
    "        lower.append(np.log(PKPD_bounds[0, pos-i_non]))\n",
    "        upper.append(np.log(PKPD_bounds[1, pos-i_non]))\n",
    "\n",
    "        lower.append(0)\n",
    "        upper.append(1.2)\n",
    "        param_names.append(pop_param_names[pos+i_mix])\n",
    "        i_mix += 1\n",
    "        param_names.append(pop_param_names[pos+i_mix])\n",
    "    elif param not in model_fixed_params:\n",
    "        lower.append(0)\n",
    "        upper.append(PKPD_bounds[1, pos-i_non])\n",
    "        param_names.append(pop_param_names[pos+i_mix])\n",
    "    elif param == \"Nonsense\":\n",
    "        i_non=1\n",
    "\n",
    "fig = plot.plot_prior(bounds=(lower, upper), param_names=param_names)\n",
    "fig.write_image(\n",
    "    PD_image_file + \"/\"\n",
    "    + PD_pop_model_file + fixed_file + \"_hyperpriors.svg\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pop_models = pop_models.copy()\n",
    "for param, x in model_fixed_params.items():\n",
    "    mix_arr = np.asarray(list(model_mixed_params.values()))\n",
    "    pos = x[1]+ np.count_nonzero(mix_arr < x[1])\n",
    "    full_pop_models.insert(pos, chi.PooledModel(n_dim=1))\n",
    "\n",
    "# plot_params = np.insert(PKPD_real_pop_params, 6, 0)\n",
    "plot = Plot_Models(chi.ComposedPopulationModel(full_pop_models), [PK_noise_model, PD_noise_model], PKPD_model, log_prior, data=df)\n",
    "fig = plot.plot_over_time(PKPD_real_pop_params, show_data=True, title=\"PK Data\", PK_PD=0)\n",
    "fig.show()\n",
    "\n",
    "fig = plot.plot_over_time(PKPD_real_pop_params, show_data=True, title=\"PD Data\", PK_PD=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Log likelihood method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10\n",
    "log_posterior = problem.get_log_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Inference import OptimisationController\n",
    "from plotly import figure_factory as ff\n",
    "\n",
    "# Set the start point for optimisation\n",
    "start_point = np.asarray(Approximations)\n",
    "start_point[list(model_mixed_params.values())] = np.log(start_point[list(model_mixed_params.values())])\n",
    "\n",
    "if len(model_mixed_params) != 0:\n",
    "    start_point = np.insert(start_point, np.asarray(list(model_mixed_params.values()))+1, 0.4)\n",
    "start_point = np.delete(\n",
    "    start_point,\n",
    "    [x[1]+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<x[1]) \n",
    "     for x in model_fixed_params.values()]\n",
    ")\n",
    "# PD_start = np.exp(0.5*np.log(PD_bounds[0])+0.5*np.log(PD_bounds[1]))\n",
    "# PK_start = np.asarray(pandas.read_csv(PK_data_file + drug+\"/opt_pop_results.csv\")['Optimised'])\n",
    "# start_point = np.concatenate((PK_start, PD_start[:-2]), axis=0)[order]\n",
    "# start_point[6] = R_0_approx # Approximation of R_0\n",
    "\n",
    "# Optimise the model with respect to the data\n",
    "optimisation = OptimisationController(\n",
    "    log_posterior\n",
    ")\n",
    "optimisation.set_n_runs(n_runs*10)\n",
    "initial_params = optimisation._initial_params\n",
    "\n",
    "i=0\n",
    "for k, ini_param in enumerate(initial_params):\n",
    "    if pandas.isna(log_posterior(ini_param)):\n",
    "        print(i, ini_param[n_ids_data:])\n",
    "        for j, param in enumerate(ini_param):\n",
    "            test_param = ini_param.copy()\n",
    "            test_param[j] = 0.5*param\n",
    "            if not pandas.isna(log_posterior(test_param)):\n",
    "                print(\"parameter \"+str(j-len(df[\"ID\"].unique()))+\" too large: \"+str(param))\n",
    "            test_param[j] = 1.5*param\n",
    "            if not pandas.isna(log_posterior(test_param)):\n",
    "                print(\"parameter \"+str(j-len(df[\"ID\"].unique()))+\" too small: \"+str(param))\n",
    "        initial_params = np.delete(initial_params, k, axis=0)\n",
    "    else:\n",
    "        i+=1\n",
    "        if i >= n_runs-1:\n",
    "            print(\"successful\")\n",
    "            break\n",
    "\n",
    "\n",
    "# loop_number = 0\n",
    "# while i<n_runs:\n",
    "#     ini_param =optimisation._initial_params[i]\n",
    "#     if pandas.isna(log_posterior(ini_param)):\n",
    "#         print(i, ini_param)\n",
    "#         for j, param in enumerate(ini_param):\n",
    "#             test_param = ini_param.copy()\n",
    "#             test_param[j] = 0.5*param\n",
    "#             if not pandas.isna(log_posterior(test_param)):\n",
    "#                 print(\"parameter \"+str(j-len(df[\"ID\"].unique()))+\" too large: \"+str(param))\n",
    "#             test_param[j] = 1.5*param\n",
    "#             if not pandas.isna(log_posterior(test_param)):\n",
    "#                 print(\"parameter \"+str(j-len(df[\"ID\"].unique()))+\" too small: \"+str(param))\n",
    "#         optimisation.set_n_runs(n_runs)\n",
    "#         i=0\n",
    "#     else:\n",
    "#         i+=1\n",
    "#     if loop_number>50:\n",
    "#         print('number of loops exceeded max')\n",
    "#         break\n",
    "#     loop_number += 1\n",
    "optimisation.set_n_runs(n_runs)\n",
    "optimisation.set_initial_point([1], [start_point])\n",
    "optimisation.set_initial_point(range(2, 1+n_runs), initial_params[:n_runs-1, n_ids_data*len(model_mixed_params):], initial_params[:n_runs-1, :n_ids_data*len(model_mixed_params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(problem.get_parameter_names()):\n",
    "    print(param, initial_params[:n_runs-1, n_ids_data*len(model_mixed_params)+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation.set_optimiser(pints.CMAES)\n",
    "optimisation.set_transform(transformation)\n",
    "optimisation.set_parallel_evaluation(True)\n",
    "result = optimisation.run(show_run_progress_bar=False, log_to_screen=False)\n",
    "\n",
    "# Show summary of optimisation\n",
    "print('Log-Posterior Value: \\t'+str(result['Score'].unique()))\n",
    "time = np.asarray(result['Time'].unique())\n",
    "print('Time Taken: \\t'+str((time/60).astype(int))+\" minutes, \"+str((time%60).astype(int))+\" seconds, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = np.empty((n_runs, len(start_point)))\n",
    "opt_ind_params = np.empty((n_runs, len(result.dropna(subset=['ID'])['ID'].unique())*len(model_mixed_params)))\n",
    "column_names = ['Parameter']\n",
    "for run in range(1,n_runs+1):\n",
    "    column_names.append('Run '+str(run))\n",
    "    run_result = result.loc[result['Run']==run]\n",
    "    # print(run, run_result.dropna(subset=['ID']))\n",
    "    parameters[run-1] = run_result.loc[run_result['ID'].isnull()]['Estimate'].values\n",
    "    opt_ind_params[run-1] = run_result.dropna(subset=['ID'])['Estimate'].values\n",
    "\n",
    "column_names = column_names + ['Mean', 'True']\n",
    "summary_data = np.concatenate((\n",
    "    [np.concatenate((np.delete(\n",
    "        pop_param_names,\n",
    "        [x[1]+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<x[1]) \n",
    "        for x in model_fixed_params.values()]\n",
    "    ), [\"Log-posterior\"]))],\n",
    "    np.concatenate((parameters, np.transpose([result['Score'].unique()])), axis=1),\n",
    "    [np.concatenate((np.mean(parameters, axis=0), [np.NaN] ))],# log_posterior(np.mean(parameters, axis=0))))],\n",
    "    [np.concatenate((np.delete(\n",
    "        PKPD_real_pop_params,\n",
    "        [x[1]+np.count_nonzero(np.asarray(list(model_mixed_params.values()))<x[1]) \n",
    "        for x in model_fixed_params.values()]\n",
    "    ), [np.NaN] ))]# log_posterior(np.delete(PKPD_actual_pop_params, [4, 5, -2]))))]\n",
    "), axis=0)\n",
    "summary_df = pandas.DataFrame(summary_data.transpose(), columns = column_names)\n",
    "\n",
    "\n",
    "summary_df.to_csv(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_opt_pop.csv\", index=False)\n",
    "np.save(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_opt_ind.npy\", opt_ind_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ind_params = np.load(PD_data_file+drug+\"/\"+PD_pop_model_file+fixed_file+\"_opt_ind.npy\")\n",
    "summary_df = pandas.read_csv(PD_data_file+drug+\"/\"+PD_pop_model_file+fixed_file+\"_opt_pop.csv\")\n",
    "\n",
    "print('Result:')\n",
    "table_df = summary_df\n",
    "table_df = table_df.set_index('Parameter').transpose()\n",
    "n_runs = len(table_df)-2\n",
    "for param, pos in model_mixed_params.items():\n",
    "    col = pop_param_names[PK_param_numbers[param]np.asarray(list(model_mixed_params.values()))<pos)]\n",
    "    param_typ = np.asarray(table_df[col])\n",
    "    param_typ[:-1] = np.exp(param_typ[:-1])\n",
    "    table_df[col] = param_typ\n",
    "rounding = dict(zip(table_df.columns, [3]*13))\n",
    "rounding[\"Log-posterior\"] = 2\n",
    "table_df = table_df.round(rounding)\n",
    "fig =  ff.create_table(table_df, index=True)\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=250,\n",
    ")\n",
    "fig.write_image(PD_image_file+\"/\"+PD_pop_model_file+fixed_file+\"_opt_table.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Plot import Plot_Models\n",
    "\n",
    "log_posterior_values = summary_df.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "log_posterior_values = np.asarray(log_posterior_values)\n",
    "\n",
    "converged = log_posterior_values>=(np.max(log_posterior_values)+np.log(0.02))\n",
    "summary_reduced = summary_df.copy()\n",
    "summary_reduced = summary_reduced.iloc[:, :-2]\n",
    "summary_reduced = summary_reduced.loc[:, np.logical_not(converged)]\n",
    "mean_of_converged = summary_df.iloc[:, :-2].loc[:, converged].mean(axis=1)\n",
    "summary_reduced[\"Mean of converged\"] = mean_of_converged\n",
    "summary_reduced[\"True\"] = summary_df[\"True\"]\n",
    "\n",
    "table = summary_reduced.transpose()\n",
    "i_mix = 0\n",
    "n_mix = len([n for n in model_mixed_params if n in PK_params])\n",
    "ind_params = np.empty((n_ids_data, len(summary_reduced) - 1 - n_mix))\n",
    "for param, pos in PK_param_numbers.items():\n",
    "    if param in model_mixed_params:\n",
    "        col = pop_param_names[pos + i_mix]\n",
    "        param_typ = np.asarray(table[col])\n",
    "        param_typ[:-1] = np.exp(param_typ[:-1])\n",
    "        table[col] = param_typ\n",
    "\n",
    "        ind_params[:, pos] = opt_ind_params[converged, i_mix::n_mix].mean(axis=0)\n",
    "        i_mix += 1\n",
    "    else:\n",
    "        ind_params[:, pos] = summary_reduced[\"Mean of converged\"].iat[pos + i_mix]\n",
    "rounding = dict(zip(table.columns, [3]*6))\n",
    "rounding[\"Log-posterior\"] = 2\n",
    "table = table.round(rounding)\n",
    "fig = ff.create_table(table, index=True)\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    ")\n",
    "fig.write_image(PD_image_file+'/'+PD_pop_model_file+\"_opt_table.svg\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "plot = Plot_Models(\n",
    "    pop_model=population_model,\n",
    "    error_models=noise_model,\n",
    "    mech_model=PK_model,\n",
    "    data=df\n",
    ")\n",
    "# summary_df = summary_df.set_index(\"Parameter\")\n",
    "# fig = plot.plot_over_time(summary_reduced[\"Mean of converged\"], ind_params=ind_params, show_data=True, doses=None, title=\"MLP Prediction\")\n",
    "# fig.write_image(PD_image_file+\"/\"+PD_pop_model_file+\"opt_graph.svg\")\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "plot_pop_params = {\"Mean of converged\": summary_reduced[\"Mean of converged\"]}\n",
    "plot_ind_params = {\"Mean of converged\": ind_params}\n",
    "for i_run, run in enumerate(summary_reduced.columns[:-2]):\n",
    "    run_pop_params = summary_reduced[run]\n",
    "    plot_pop_params[\"Failed \" + run] = run_pop_params[:-1]\n",
    "    ind_params = np.empty((n_ids_data, len(summary_reduced) - 1 - n_mix))\n",
    "    i_mix = 0\n",
    "    for param, pos in PK_param_numbers.items():\n",
    "        if param in model_mixed_params:\n",
    "            ind_params[:, pos] = opt_ind_params[np.logical_not(converged), i_mix::n_mix][i_run]\n",
    "            i_mix += 1\n",
    "        else:\n",
    "            ind_params[:, pos] = run_pop_params[pos + i_mix]\n",
    "    plot_ind_params[\"Failed \" + run] = ind_params\n",
    "\n",
    "fig = plot.plot_over_time(plot_pop_params, ind_params=plot_ind_params, show_data=True, doses=None, title=\"MLP Prediction\", highlight_first=True)\n",
    "fig.write_image(PD_image_file+\"/\"+PD_pop_model_file+\"PD_opt_graph.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from math import floor\n",
    "\n",
    "n_times = 1000\n",
    "n_ids = 1000\n",
    "\n",
    "\n",
    "PK_time_span = df.loc[df[\"Observable\"]==\"PK_central.drug_concentration\"][\"Time\"].max()\n",
    "PD_time_span = df.loc[df[\"Observable\"]==\"circulating.R\"][\"Time\"].max()\n",
    "more_PK_times = np.linspace(\n",
    "    start=0, stop=1.01*(PK_time_span-dose_time), num=n_times\n",
    ")\n",
    "more_PD_times = np.linspace(\n",
    "    start=-dose_time, stop=1.01*(PD_time_span-dose_time), num=n_times\n",
    ")\n",
    "\n",
    "# Plot the PK Observations\n",
    "fig1 = make_subplots(rows=4, cols=3, shared_xaxes=True, shared_yaxes=True)\n",
    "fig2 = make_subplots(rows=4, cols=3, shared_xaxes=True, shared_yaxes=True)\n",
    "\n",
    "non_pop_parameters = np.insert(PKPD_real_params[1], 6, 0.0)\n",
    "\n",
    "for run in range(0, n_runs):\n",
    "    row = floor(run/3)+1\n",
    "    col = run%3+1\n",
    "    print(row, col)\n",
    "    inferred_pop_params = np.asarray(summary_df['Run '+str(run+1)])[:-1]\n",
    "    avg_inferred = inferred_pop_params\n",
    "    for x in all_params:\n",
    "        if x in model_fixed_params:\n",
    "            avg_inferred = np.insert(\n",
    "                avg_inferred,\n",
    "                model_fixed_params[x][1],\n",
    "                non_pop_parameters[model_fixed_params[x][1]]\n",
    "            )\n",
    "        elif x in model_mixed_params:\n",
    "            avg_inferred = np.delete(avg_inferred, model_mixed_params[x]+1) # log V_c std.\n",
    "            avg_inferred[model_mixed_params[x]] = np.exp(avg_inferred[model_mixed_params[x]]) # V_c mean\n",
    "\n",
    "    sim_ind_params = population_model.sample(\n",
    "        parameters=inferred_pop_params,\n",
    "        n_samples=n_ids\n",
    "    )\n",
    "    # Plot the population model for each dose\n",
    "    ind = 0\n",
    "    for i, group in enumerate(dose_groups):\n",
    "        # Simulate and Plot from the population maximum likelihood estimation\n",
    "        amt = dose_amts[i]\n",
    "        PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "        more_PK_values = PKPD_model.simulate(\n",
    "            avg_inferred[:-2],\n",
    "            more_PK_times+dose_time\n",
    "        )[0]\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=more_PK_times,\n",
    "                y=more_PK_values,\n",
    "                mode='lines',\n",
    "                line=dict(color=ind_colours[i, int(n_per_dose[group]/2)], dash='dash'),\n",
    "                name='Typical simulation',\n",
    "                legendgroup= group,\n",
    "                # legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        more_PD_values = PKPD_model.simulate(avg_inferred[:-2], more_PD_times)[1]\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=more_PD_times,\n",
    "                y=more_PD_values,\n",
    "                mode='lines',\n",
    "                line=dict(color=ind_colours[i, int(n_per_dose[group]/2)], dash='dash'),\n",
    "                name='Typical simulation',\n",
    "                legendgroup= group,\n",
    "                legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        for j, patient in enumerate(df.loc[df['Dose group']==group]['ID'].unique()):\n",
    "            PKPD_model.set_dosing_regimen(\n",
    "                df.loc[(df['ID']==patient) & df['Observable'].isna()]['Dose'].iat[0], \n",
    "                start=dose_time,\n",
    "                period=0\n",
    "            )\n",
    "            ind_real_params = avg_inferred.copy()\n",
    "            for i_mix, pos in enumerate(model_mixed_params.values()):\n",
    "                ind_real_params[pos] = opt_ind_params[run, ind*len(model_mixed_params) + i_mix]\n",
    "            if group!=0.0:\n",
    "                individual_PK_values = PKPD_model.simulate(\n",
    "                    ind_real_params[:-2],\n",
    "                    more_PK_times+dose_time\n",
    "                )[0]\n",
    "                fig1.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=more_PK_times,\n",
    "                        y=individual_PK_values,\n",
    "                        name='Individual simulation',\n",
    "                        legendgroup = group,\n",
    "                        showlegend= False,\n",
    "                        mode=\"lines\",\n",
    "                        line=go.scatter.Line(color=ind_colours[i, j], width=0.5),\n",
    "                        opacity=0.5,\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col\n",
    "                )\n",
    "                x_data = df_PK_graph.loc[df_PK_graph['ID']==patient][x_label]-dose_time\n",
    "                y_data = df_PK_graph.loc[df_PK_graph['ID']==patient][PK_y_label]\n",
    "                fig1.add_trace(go.Scatter(\n",
    "                    x=x_data,\n",
    "                    y=y_data,\n",
    "                    mode='markers',\n",
    "                    marker_color=ind_colours[i, j],\n",
    "                    name='Data',\n",
    "                    legendgroup = group,\n",
    "                    showlegend = False,\n",
    "                ),row=row, col=col)\n",
    "            individual_PD_values = PKPD_model.simulate(\n",
    "                ind_real_params[:-2],\n",
    "                more_PD_times+dose_time\n",
    "            )[1]\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=more_PD_times,\n",
    "                    y=individual_PD_values,\n",
    "                    name='Individual simulation',\n",
    "                    legendgroup = group,\n",
    "                    showlegend= False,\n",
    "                    mode=\"lines\",\n",
    "                    line=go.scatter.Line(color=ind_colours[i, j], width=0.5),\n",
    "                    opacity=0.5,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            x_data = df_PD_graph.loc[df_PD_graph['ID']==patient][x_label]-dose_time\n",
    "            y_data = df_PD_graph.loc[df_PD_graph['ID']==patient][PD_y_label]\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_data,\n",
    "                    y=y_data,\n",
    "                    mode='markers',\n",
    "                    marker_color=ind_colours[i, j],\n",
    "                    name='Data',\n",
    "                    legendgroup = group,\n",
    "                    showlegend = False,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            ind+=1\n",
    "    \n",
    "        PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "        if group!=0.0:\n",
    "            # Find 5th to 95th percentile of population distribution\n",
    "            PK_simulations = np.empty(shape=(n_ids, n_times))\n",
    "            PD_simulations = np.empty(shape=(n_ids, n_times))\n",
    "            for idd, patient_parameters in enumerate(sim_ind_params):\n",
    "                ind_param = patient_parameters.copy()\n",
    "                for x in model_fixed_params.values():\n",
    "                    ind_param = np.insert(\n",
    "                        ind_param,\n",
    "                        x[1],\n",
    "                        non_pop_parameters[x[1]]\n",
    "                    )\n",
    "                # The solver has difficulties when V_c is too small (creates infinite drug concentration)\n",
    "                if ind_param[2]<1e-10:\n",
    "                    # PK_simulations[idd] = [np.inf]*len(more_PK_times)\n",
    "                    # PD_simulations[idd] = [ind_param[2]]*np.count_nonzero(more_PD_times<0)+[0]*np.count_nonzero(more_PD_times>=0)\n",
    "                    ind_param[2]=1e-10\n",
    "                ind_sim = PKPD_model.simulate(\n",
    "                    ind_param[:-2],\n",
    "                    more_PK_times+dose_time\n",
    "                )[0]\n",
    "                PK_simulations[idd] = PK_noise_model.sample(\n",
    "                    ind_param[-2:-1], ind_sim)[:, 0]\n",
    "                ind_sim = PKPD_model.simulate(\n",
    "                    ind_param[:-2],\n",
    "                    more_PD_times + dose_time\n",
    "                )[1]\n",
    "                PD_simulations[idd] = PD_noise_model.sample(\n",
    "                    ind_param[-1:], ind_sim)[:, 0]\n",
    "            \n",
    "            # Plot the variability\n",
    "            fifth = np.percentile(PK_simulations, q=5, axis=0)\n",
    "            ninety_fifth = np.percentile(PK_simulations, q=95, axis=0)\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=np.hstack([more_PK_times, more_PK_times[::-1]]),\n",
    "                    y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                    line=dict(\n",
    "                        width=0,\n",
    "                        color=ind_colours[i, int(n_per_dose[group]/2)]\n",
    "                    ),\n",
    "                    fill='toself',\n",
    "                    name='Population model',\n",
    "                    text=r\"90% bulk probability\",\n",
    "                    hoverinfo='text',\n",
    "                    legendgroup= group,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            \n",
    "        # Plot the variability\n",
    "        fifth = np.percentile(PD_simulations, q=5, axis=0)\n",
    "        ninety_fifth = np.percentile(PD_simulations, q=95, axis=0)\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.hstack([more_PD_times, more_PD_times[::-1]]),\n",
    "                y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                line=dict(\n",
    "                    width=0,\n",
    "                    color=ind_colours[i, int(n_per_dose[group]/2)]\n",
    "                ),\n",
    "                fill='toself',\n",
    "                name='Population model',\n",
    "                text=r\"90% bulk probability\",\n",
    "                hoverinfo='text',\n",
    "                legendgroup= group,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "    if run == 0:\n",
    "        axis = ''\n",
    "    else:\n",
    "        axis = str(run+1)\n",
    "    if col == 1:\n",
    "        fig1['layout']['yaxis'+axis].update(title_text = PK_y_label, range=[np.log10(np.min(df_PK_graph[PK_y_label])/1.6), np.log10(1.6*np.max(df_PK_graph[PK_y_label]))])\n",
    "        fig2['layout']['yaxis'+axis].update(title_text = PD_y_label, range=[np.min(df_PD_graph[PD_y_label])*0.9, 1.1*np.max(df_PD_graph[PD_y_label])])\n",
    "\n",
    "    fig1['layout']['yaxis'+axis].update(type=\"log\", minor=dict(dtick='D1', showgrid=True), dtick = 1)\n",
    "    fig1['layout']['xaxis'+axis].update(dtick = 1, title_text = x_label)\n",
    "    fig2['layout']['yaxis'+axis].update(dtick = 250)\n",
    "    fig2['layout']['xaxis'+axis].update(dtick = 72, minor=dict(dtick=24, showgrid=True), title_text = x_label)\n",
    "\n",
    "fig1.update_layout(\n",
    "    width=1100,\n",
    "    height=750,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig2.update_layout(\n",
    "    width=1100,\n",
    "    height=750,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig1.write_image(PD_image_file + \"/\" + PD_pop_model_file+fixed_file+\"_PK_opt_graph.svg\")\n",
    "fig2.write_image(PD_image_file + \"/\" + PD_pop_model_file+fixed_file+\"_PD_opt_graph.svg\")\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison of fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_scenarios = [[\"K_cl\", \"K_1\", \"V_1\", \"sigma_PK\"], [\"K_1\", \"V_1\", \"sigma_PK\"], [\"V_1\", \"sigma_PK\"], [\"sigma_PK\"], []]\n",
    "# log_posterior = problem.get_log_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferred_pop_params = pandas.read_csv(PD_data_file+drug+\"/opt_pop_results\"+fixed_param[\"\\sigma_{PK}\"]+\".csv\")\n",
    "# inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "# log_posterior_values = inferred_pop_params.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "# log_posterior_values = np.asarray(log_posterior_values)\n",
    "# converged = log_posterior_values>=(np.max(log_posterior_values)+np.log(0.02))\n",
    "# table = inferred_pop_params.iloc[:, :10]\n",
    "# table = table.loc[:, np.logical_not(converged)]\n",
    "# mean_of_converged = inferred_pop_params.iloc[:, :10].loc[:, converged].mean(axis=1)\n",
    "# table[\"Mean of converged\"] = mean_of_converged\n",
    "# table[\"True\"] = inferred_pop_params[\"True\"]\n",
    "# inferred_pop_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_of_pop_params = {}\n",
    "\n",
    "for scenario in fixed_scenarios:\n",
    "    fixed_file_compare = \"\"\n",
    "    if len(scenario)>0:\n",
    "        fixed_file_compare += \"_fixed\"\n",
    "        for param in scenario:\n",
    "            fixed_file_compare += \"_\"+param\n",
    "    \n",
    "    inferred_pop_params = pandas.read_csv(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_opt_pop.csv\")\n",
    "    opt_ind_params = np.load(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_opt_ind.npy\")\n",
    "    inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "    try:\n",
    "        log_posterior_values = inferred_pop_params.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "        log_posterior_values = np.asarray(log_posterior_values)\n",
    "    except KeyError:\n",
    "        print(\"calculating posterior values for model with \"+np.char.join(\", \", scenario)+\" PK parameters fixed\")\n",
    "        log_posterior_values = []\n",
    "        for i in range(1, len(inferred_pop_params.columns)-1):\n",
    "            params = inferred_pop_params['Run ' +str(i)]\n",
    "            params = np.concatenate((opt_ind_params[i-1], params))\n",
    "            log_posterior_values.append(log_posterior(params))\n",
    "        inferred_pop_params.loc[\"Log-posterior\"] = np.concatenate((log_posterior_values, [np.NaN, np.NaN]))\n",
    "        inferred_pop_params = inferred_pop_params.reset_index(names='Parameter')\n",
    "        inferred_pop_params.to_csv(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_opt_pop.csv\", index=False)\n",
    "        inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "\n",
    "    converged = log_posterior_values>=(np.max(log_posterior_values)+np.log(0.02))\n",
    "    table = inferred_pop_params.iloc[:, :-2]\n",
    "    table = table.loc[:, np.logical_not(converged)]\n",
    "    mean_of_converged = inferred_pop_params.iloc[:, :10].loc[:, converged].mean(axis=1)\n",
    "    table[\"Mean of converged\"] = mean_of_converged\n",
    "    table[\"True\"] = inferred_pop_params[\"True\"]\n",
    "\n",
    "    table_of_pop_params[scenario] = table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "n_times = 1000\n",
    "n_ids = 1000\n",
    "PD_time_span = df.loc[df[\"Observable\"]==\"circulating.R\"][\"Time\"].max()\n",
    "more_PD_times = np.linspace(\n",
    "    start=-dose_time, stop=1.01*(PD_time_span-dose_time), num=n_times\n",
    ")\n",
    "\n",
    "non_pop_parameters = np.insert(PKPD_real_params[1], 6, 0.0)\n",
    "\n",
    "for scenario in fixed_scenarios:\n",
    "    fixed_file_compare = \"\"\n",
    "    if len(scenario)>0:\n",
    "        fixed_file_compare += \"_fixed\"\n",
    "        for param in scenario:\n",
    "            fixed_file_compare += \"_\"+param\n",
    "\n",
    "    table = table_of_pop_params[scenario]\n",
    "    fig = make_subplots(rows=1, cols=len(table.columns)+2,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.01,\n",
    "        horizontal_spacing=0.01,\n",
    "        specs=[[{\"type\": \"table\", \"colspan\": 3}, None, None]+[{\"type\": \"scatter\"}]*(len(table.columns)-1)])\n",
    "\n",
    "    # First subplot is table\n",
    "    display_table = table.copy()\n",
    "    for param, pos in model_mixed_params.items():\n",
    "        param_typ = np.asarray(display_table[PKPD_real_params[pos]])\n",
    "        param_typ[:-1] = np.exp(param_typ[:-1])\n",
    "        display_table[PKPD_real_params[pos]] = param_typ\n",
    "    rounding = dict(zip(display_table.columns, [3]*13))\n",
    "    rounding[\"Log-posterior\"] = 2\n",
    "    display_table = display_table.rename(index = {'Log-posterior': 'Log-post'}, columns = {'Mean of converged': 'Converged'})\n",
    "    display_table = display_table.round(rounding) # Round the values in the table for viewability\n",
    "    display_table = display_table.reset_index(names='Parameter')\n",
    "\n",
    "    fig.add_trace(go.Table(\n",
    "            header=dict(values=list(display_table.columns)),\n",
    "            cells=dict(values=display_table.to_numpy().transpose()),\n",
    "            columnwidth=[2]+[1]*len(table.columns),\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Rest of the Subplots are for graphing outliers\n",
    "    for run, col in enumerate(table.columns):\n",
    "        inferred_pop_params = np.asarray(table[col])[:-1]\n",
    "        avg_inferred = inferred_pop_params\n",
    "        for x in all_params:\n",
    "            if x in scenario:\n",
    "                avg_inferred = np.insert(\n",
    "                    avg_inferred,\n",
    "                    PKPD_param_numbers[x],\n",
    "                    non_pop_parameters[PKPD_param_numbers[x]]\n",
    "                )\n",
    "            elif x in model_mixed_params:\n",
    "                avg_inferred = np.delete(avg_inferred, model_mixed_params[x]+1) # log V_c std.\n",
    "                avg_inferred[model_mixed_params[x]] = np.exp(avg_inferred[model_mixed_params[x]]) # V_c mean\n",
    "\n",
    "        sim_ind_params = population_model.sample(\n",
    "            parameters=inferred_pop_params,\n",
    "            n_samples=n_ids\n",
    "        )\n",
    "        # Plot the population model for each dose\n",
    "        ind = 0\n",
    "        for i, group in enumerate(dose_groups):\n",
    "            # Simulate and Plot from the population maximum likelihood estimation\n",
    "            amt = dose_amts[i]\n",
    "            PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "            more_PD_values = PKPD_model.simulate(avg_inferred[:-2], more_PD_times)[1]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=more_PD_times,\n",
    "                    y=more_PD_values,\n",
    "                    mode='lines',\n",
    "                    line=dict(color=ind_colours[i, int(n_per_dose[group]/2)], dash='dash'),\n",
    "                    name='Typical simulation',\n",
    "                    legendgroup= group,\n",
    "                    legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1,\n",
    "                col=run+3\n",
    "            )\n",
    "            for j, patient in enumerate(df.loc[df['Dose group']==group]['ID'].unique()):\n",
    "                PKPD_model.set_dosing_regimen(\n",
    "                    df.loc[(df['ID']==patient) & df['Observable'].isna()]['Dose'].iat[0], \n",
    "                    start=dose_time,\n",
    "                    period=0\n",
    "                )\n",
    "                # individual_parameters = avg_inferred.copy()\n",
    "                # individual_parameters[2] = opt_ind_params[run, ind]\n",
    "                # individual_PD_values = PKPD_model.simulate(\n",
    "                #     individual_parameters[:-2],\n",
    "                #     more_PD_times+dose_time\n",
    "                # )[1]\n",
    "                # fig.add_trace(\n",
    "                #     go.Scatter(\n",
    "                #         x=more_PD_times,\n",
    "                #         y=individual_PD_values,\n",
    "                #         name='Individual simulation',\n",
    "                #         legendgroup = group,\n",
    "                #         showlegend= False,\n",
    "                #         mode=\"lines\",\n",
    "                #         line=go.scatter.Line(color=ind_colour_selection[i, j], width=0.5),\n",
    "                #         opacity=0.5,\n",
    "                #     ),\n",
    "                #     row=1,\n",
    "                #     col=run+4\n",
    "                # )\n",
    "                x_data = df_PD_graph.loc[df_PD_graph['ID']==patient][x_label]-dose_time\n",
    "                y_data = df_PD_graph.loc[df_PD_graph['ID']==patient][PD_y_label]\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=x_data,\n",
    "                        y=y_data,\n",
    "                        mode='markers',\n",
    "                        marker_color=ind_colours[i, j],\n",
    "                        name='Data',\n",
    "                        legendgroup = group,\n",
    "                        showlegend = False,\n",
    "                    ),\n",
    "                    row=1,\n",
    "                    col=run+4\n",
    "                )\n",
    "                ind+=1\n",
    "        \n",
    "            PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "            if group!=0.0:\n",
    "                # Find 5th to 95th percentile of population distribution\n",
    "                PD_simulations = np.empty(shape=(n_ids, n_times))\n",
    "                for idd, patient_parameters in enumerate(sim_ind_params):\n",
    "                    ind_param = patient_parameters.copy()\n",
    "                    for x in scenario:\n",
    "                        ind_param = np.insert(\n",
    "                            ind_param,\n",
    "                            PKPD_param_numbers[x],\n",
    "                            non_pop_parameters[PKPD_param_numbers[x]]\n",
    "                        )\n",
    "                    ind_sim = PKPD_model.simulate(\n",
    "                        ind_param[:-2],\n",
    "                        more_PD_times + dose_time\n",
    "                    )[1]\n",
    "                    PD_simulations[idd] = PD_noise_model.sample(\n",
    "                        ind_param[-1:], ind_sim)[:, 0]\n",
    "                \n",
    "            # Plot the variability\n",
    "            fifth = np.percentile(PD_simulations, q=5, axis=0)\n",
    "            ninety_fifth = np.percentile(PD_simulations, q=95, axis=0)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=np.hstack([more_PD_times, more_PD_times[::-1]]),\n",
    "                    y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                    line=dict(\n",
    "                        width=0,\n",
    "                        color=ind_colours[i, int(n_per_dose[group]/2)]\n",
    "                    ),\n",
    "                    fill='toself',\n",
    "                    name='Population model',\n",
    "                    text=r\"90% bulk probability\",\n",
    "                    hoverinfo='text',\n",
    "                    legendgroup= group,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1,\n",
    "                col=run+4\n",
    "            )\n",
    "        # if run == 0:\n",
    "        #     axis = ''\n",
    "        else:\n",
    "            axis = str(run+4)\n",
    "        fig2['layout']['yaxis'+axis].update(dtick = 250, title_text = PD_y_label)\n",
    "        fig2['layout']['xaxis'+axis].update(dtick = 72, minor=dict(dtick=24, showgrid=True), title_text = x_label)\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1100,\n",
    "            height=750,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        fig.write_image(PD_image_file+\"/\"+PD_pop_model_file+fixed_file+\"_compare_opt_graph.svg\")\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further adjustables\n",
    "num_samples = 1500  # number of wanted final samples from all runs\n",
    "max_runs = 5\n",
    "r_hat_criteria = 1.1\n",
    "log_posterior = problem.get_log_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Code.Inference import SamplingController\n",
    "# import xarray as xr\n",
    "# sampler = SamplingController(log_posterior)\n",
    "# sampler.set_n_runs(max_runs)\n",
    "\n",
    "# previous_samples = xr.open_dataset(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_samples.nc\")\n",
    "# sampler.reset_chains()\n",
    "# sampler.add_samples(previous_samples)\n",
    "# previous_samples.close()\n",
    "\n",
    "# sampler.set_sampler(pints.NoUTurnMCMC)\n",
    "# sampler.set_stop_criterion(max_iterations=int(num_samples/max_runs)+200, r_hat=r_hat_criteria)\n",
    "# sampler.set_transform(transformation)\n",
    "# posterior_samples = sampler.run(\n",
    "#     n_iterations=int(num_samples/max_runs)+200,\n",
    "#     log_to_screen=True,\n",
    "#     reset=False\n",
    "# )\n",
    "# posterior_samples.to_netcdf(PD_data_file+drug+PD_pop_model_file+fixed_file+\"_samples.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code.Inference import SamplingController\n",
    "sampler = SamplingController(log_posterior)\n",
    "sampler.set_n_runs(max_runs)\n",
    "\n",
    "# ini_param = log_posterior.sample_initial_parameters(n_samples=max_runs*100)\n",
    "# n_successful = 0\n",
    "# for i in range(0, max_runs*100):\n",
    "#     lp = log_posterior(ini_param[i])\n",
    "#     if not(pandas.isna(lp) or (lp <= -1e8)):\n",
    "#         n_successful += 1\n",
    "#         top_param =ini_param[i, len(df['ID'].unique()):]\n",
    "#         bottom_param = ini_param[i, :len(df['ID'].unique())]\n",
    "#         sampler.set_initial_point(n_successful, top_param, bottom_param)\n",
    "#         print(lp)\n",
    "#     if n_successful==max_runs:\n",
    "#         print(\"Successful Sample after\", i, \"Generations\")\n",
    "#         break\n",
    "#     if i==max_runs*100-1:\n",
    "#         print(\n",
    "#              \"Unsuccessful Sample, only\",\n",
    "#              n_successful,\n",
    "#              \"parameter sets accquired\"\n",
    "#         )\n",
    "\n",
    "inferred_pop_params = pandas.read_csv(\n",
    "    PD_data_file + drug\n",
    "    + PD_pop_model_file + fixed_file\n",
    "    + \"_opt_pop.csv\"\n",
    ")\n",
    "opt_ind_params = np.load(\n",
    "    PD_data_file + drug\n",
    "    + PD_pop_model_file + fixed_file\n",
    "    + \"_opt_ind.npy\"\n",
    ")\n",
    "\n",
    "inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "try:\n",
    "    log_posterior_values = inferred_pop_params.loc[\"Log-posterior\"].drop([\"Mean\", \"True\"])\n",
    "    log_posterior_values = np.asarray(log_posterior_values)\n",
    "except KeyError:\n",
    "    print(\n",
    "        \"calculating posterior values for model with \" +\n",
    "        np.char.join(\", \", scenario) +\n",
    "        \" PK parameters fixed\"\n",
    "    )\n",
    "    log_posterior_values = []\n",
    "    for i in range(1, len(inferred_pop_params.columns)-1):\n",
    "        params = inferred_pop_params['Run '+str(i)]\n",
    "        params = np.concatenate((opt_ind_params[i-1], params))\n",
    "        log_posterior_values.append(log_posterior(params))\n",
    "    inferred_pop_params.loc[\"Log-posterior\"] = np.concatenate((\n",
    "        log_posterior_values, [np.NaN, np.NaN]\n",
    "    ))\n",
    "    inferred_pop_params = inferred_pop_params.reset_index(names='Parameter')\n",
    "    inferred_pop_params.to_csv((\n",
    "        PD_data_file + drug +\n",
    "        PD_pop_model_file + fixed_file +\n",
    "        \"_opt_pop.csv\"\n",
    "    ), index=False)\n",
    "    inferred_pop_params = inferred_pop_params.set_index(\"Parameter\")\n",
    "\n",
    "converged = log_posterior_values >= (np.max(log_posterior_values)+np.log(0.02))\n",
    "n_runs = np.count_nonzero(converged)\n",
    "\n",
    "if n_runs < 3:\n",
    "    print(\n",
    "        \"Not enough consistent results from the Maximum\"+\n",
    "        \"Likelihood Estimation to start Sampling\"\n",
    "    )\n",
    "else:\n",
    "    if n_runs >= max_runs:\n",
    "        n_runs = max_runs\n",
    "    sampler.set_n_runs(n_runs)\n",
    "    opt_params = (\n",
    "        inferred_pop_params.drop(columns=['Mean', 'True']).values[:, converged]\n",
    "    )[:-1, :n_runs]\n",
    "    ind_params = (opt_ind_params[converged])[:n_runs]\n",
    "    sampler.set_initial_point(\n",
    "        range(1, n_runs+1), opt_params.transpose(), ind_params\n",
    "    )\n",
    "    for i, param in enumerate(population_model.get_parameter_names()):\n",
    "        print(param, opt_params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_0 = None\n",
    "sampler.set_sampler(pints.NoUTurnMCMC)\n",
    "sampler.set_stop_criterion(\n",
    "    max_iterations=int(num_samples/n_runs)+100,\n",
    "    r_hat=r_hat_criteria\n",
    ")\n",
    "sampler.set_transform(transformation)\n",
    "posterior_samples = sampler.run(\n",
    "    n_iterations=int(num_samples/n_runs)+100, sigma0=cov_0\n",
    ")\n",
    "posterior_samples.to_netcdf(\n",
    "    PD_data_file+drug+PD_pop_model_file+fixed_file+\"_samples.nc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "posterior_samples = xr.open_dataset(\n",
    "    PD_data_file+drug+PD_pop_model_file+fixed_file+\"_samples.nc\"\n",
    ").load()\n",
    "n_runs=len(posterior_samples.chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "az.style.use([\"arviz-white\",  \"arviz-viridish\"])\n",
    "\n",
    "lines = list(zip(*(\n",
    "    population_model.get_parameter_names(),\n",
    "    [{}]*len(population_model.get_parameter_names()),\n",
    "    np.delete(PKPD_real_pop_params, [4, 5, -2]))))\n",
    "actual_ind_Vc = np.load(PD_data_file + drug+\"/ind_Vc_param.npy\")\n",
    "lines = lines+[(\n",
    "    \"PK_central.V_c\",\n",
    "    dict([[\n",
    "        \"individual\", df['ID'].unique()\n",
    "    ]]),\n",
    "    actual_ind_Vc\n",
    ")]\n",
    "# lines[1] = (\n",
    "#     '',# population_model.get_parameter_names()[1],\n",
    "#     {},\n",
    "#     np.exp(PKPD_actual_pop_params[1])\n",
    "# )\n",
    "lines[2] = (\n",
    "    population_model.get_parameter_names()[2],\n",
    "    {},\n",
    "    np.exp(PKPD_real_pop_params[2])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_tansform(params_to_trans):\n",
    "    trans_param = params_to_trans\n",
    "    try:\n",
    "        trans_param['Log mean '+param] = np.exp(trans_param['Log mean '+param])\n",
    "    except:\n",
    "        pass\n",
    "    return trans_param\n",
    "\n",
    "# Discard warmup iterations\n",
    "discard = max(len(posterior_samples.draw)-int(num_samples/n_runs), 1)\n",
    "main_samples = posterior_samples.drop_isel(draw=slice(0, discard))\n",
    "\n",
    "print(\"R-hat value:\", az.rhat(main_samples))\n",
    "\n",
    "for param in np.delete(PKPD_model.parameters(), [3, 4, 6]):\n",
    "    az.plot_trace(\n",
    "        main_samples,\n",
    "        var_names=('.*'+param),\n",
    "        filter_vars=\"regex\",\n",
    "        lines=lines,\n",
    "        transform=graph_tansform\n",
    "    )\n",
    "    param_name = param.split('.')[-1]\n",
    "    plt.savefig(\n",
    "        PD_image_file + \"/\" +\n",
    "        PD_pop_model_file + fixed_file +\n",
    "        \"MCMC_\"+param_name+\"_trace.svg\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "az.plot_trace(main_samples, var_names=('.*Sigma'), filter_vars=\"regex\", lines=lines)\n",
    "plt.savefig(\n",
    "    PD_image_file + \"/\" +\n",
    "    PD_pop_model_file + fixed_file +\n",
    "    \"MCMC_noise_trace.svg\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from math import floor\n",
    "\n",
    "n_times = 1000\n",
    "n_ids = 100  # number of ids to generate per sample for determining percentiles\n",
    "n_samples_per = 100 # number of samples to select for determining percentiles\n",
    "\n",
    "PK_time_span = df.loc[df[\"Observable\"]==\"PK_central.drug_concentration\"][\"Time\"].max()\n",
    "PD_time_span = df.loc[df[\"Observable\"]==\"circulating.R\"][\"Time\"].max()\n",
    "more_PK_times = np.linspace(\n",
    "    start=0, stop=1.01*(PK_time_span-dose_time), num=n_times\n",
    ")\n",
    "more_PD_times = np.linspace(\n",
    "    start=-dose_time, stop=1.01*(PD_time_span-dose_time), num=n_times\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Plot the PK Observations\n",
    "fig1 = make_subplots(rows=4, cols=3, shared_xaxes=True, shared_yaxes=True)\n",
    "fig2 = make_subplots(rows=4, cols=3, shared_xaxes=True, shared_yaxes=True)\n",
    "\n",
    "for run in range(0, n_runs):\n",
    "    row = floor(run/3)+1\n",
    "    col = run%3+1\n",
    "    print(row, col)\n",
    "    sampled_params = main_samples.isel(chain=[run])\n",
    "    mean_samples = sampled_params.mean(dim=\"draw\")\n",
    "    avg_inferred = np.asarray(mean_samples.drop(['PK_central.V_c']).to_array()).flatten()\n",
    "    # avg_inferred = np.insert(avg_inferred, 1, PK_opt_params[0]) # Clearance\n",
    "    avg_inferred[2] = np.exp(avg_inferred[2]) # V_c mean\n",
    "    avg_inferred = np.delete(avg_inferred, [3]) # log V_c std.\n",
    "    avg_inferred = np.insert(avg_inferred, 3, PK_opt_params[3]) # Periferal Parameters\n",
    "    avg_inferred = np.insert(avg_inferred, 4, PK_opt_params[4]) # Periferal Parameters\n",
    "    avg_inferred = np.insert(avg_inferred, 6, 0) # Nonsense paremeter\n",
    "    avg_inferred = np.insert(avg_inferred, -1, PK_opt_params[-1]) # PK Noise parameter\n",
    "\n",
    "    \n",
    "    # sim_ind_params = population_model.sample(\n",
    "    #     parameters=inferred_pop_params,\n",
    "    #     n_samples=n_ids\n",
    "    # )\n",
    "    \n",
    "    per_ind_params = np.empty((0,7))\n",
    "    per_samples = az.extract(sampled_params, num_samples=n_samples_per)\n",
    "    for s in per_samples.coords['sample']:\n",
    "        param = np.asarray(per_samples.drop(['PK_central.V_c']).sel(sample=s).to_array()).flatten()\n",
    "        per_ind_params = np.concatenate((per_ind_params, population_model.sample(\n",
    "            parameters=param,\n",
    "            n_samples=n_ids\n",
    "        )), axis = 0)\n",
    "\n",
    "    # Plot the population model for each dose\n",
    "    for i, group in enumerate(dose_groups):\n",
    "        # Simulate and Plot from the population mean\n",
    "        amt = dose_amts[i]\n",
    "        PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "        more_PK_values = PKPD_model.simulate(\n",
    "            avg_inferred[:-2],\n",
    "            more_PK_times+dose_time\n",
    "        )[0]\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=more_PK_times,\n",
    "                y=more_PK_values,\n",
    "                mode='lines',\n",
    "                line=dict(color=ind_colours[i, int(n_ids_data/2)], dash='dash'),\n",
    "                name='Typical simulation',\n",
    "                legendgroup= group,\n",
    "                # legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        more_PD_values = PKPD_model.simulate(avg_inferred[:-2], more_PD_times)[1]\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=more_PD_times,\n",
    "                y=more_PD_values,\n",
    "                mode='lines',\n",
    "                line=dict(color=ind_colours[i, int(n_ids_data/2)], dash='dash'),\n",
    "                name='Typical simulation',\n",
    "                legendgroup= group,\n",
    "                legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "        for j, patient in enumerate(df.loc[df['Dose group']==group]['ID'].unique()):\n",
    "            PKPD_model.set_dosing_regimen(\n",
    "                df.loc[(df['ID']==patient) & df['Observable'].isna()]['Dose'].iat[0], \n",
    "                start=dose_time,\n",
    "                period=0\n",
    "            )\n",
    "            ind_real_params = avg_inferred.copy()\n",
    "            ind_real_params[2] = mean_samples['PK_central.V_c'].sel(individual=str(patient)).item()\n",
    "            if group!=0.0:\n",
    "                individual_PK_values = PKPD_model.simulate(\n",
    "                    ind_real_params[:-2],\n",
    "                    more_PK_times+dose_time\n",
    "                )[0]\n",
    "                fig1.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=more_PK_times,\n",
    "                        y=individual_PK_values,\n",
    "                        name='Individual simulation',\n",
    "                        legendgroup = group,\n",
    "                        showlegend= False,\n",
    "                        mode=\"lines\",\n",
    "                        line=go.scatter.Line(color=ind_colours[i, j], width=0.5),\n",
    "                        opacity=0.5,\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col\n",
    "                )\n",
    "                x_data = df_PK_graph.loc[df_PK_graph['ID']==patient][x_label]-dose_time\n",
    "                y_data = df_PK_graph.loc[df_PK_graph['ID']==patient][PK_y_label]\n",
    "                fig1.add_trace(go.Scatter(\n",
    "                    x=x_data,\n",
    "                    y=y_data,\n",
    "                    mode='markers',\n",
    "                    marker_color=ind_colours[i, j],\n",
    "                    name='Data',\n",
    "                    legendgroup = group,\n",
    "                    showlegend = False,\n",
    "                ),row=row, col=col)\n",
    "            individual_PD_values = PKPD_model.simulate(\n",
    "                ind_real_params[:-2],\n",
    "                more_PD_times+dose_time\n",
    "            )[1]\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=more_PD_times,\n",
    "                    y=individual_PD_values,\n",
    "                    name='Individual simulation',\n",
    "                    legendgroup = group,\n",
    "                    showlegend= False,\n",
    "                    mode=\"lines\",\n",
    "                    line=go.scatter.Line(color=ind_colours[i, j], width=0.5),\n",
    "                    opacity=0.5,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            x_data = df_PD_graph.loc[df_PD_graph['ID']==patient][x_label]-dose_time\n",
    "            y_data = df_PD_graph.loc[df_PD_graph['ID']==patient][PD_y_label]\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_data,\n",
    "                    y=y_data,\n",
    "                    mode='markers',\n",
    "                    marker_color=ind_colours[i, j],\n",
    "                    name='Data',\n",
    "                    legendgroup = group,\n",
    "                    showlegend = False,\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            \n",
    "        PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "        if group!=0.0:\n",
    "            # Find 5th to 95th percentile of population distribution\n",
    "            PK_simulations = np.empty(shape=(len(per_ind_params), n_times))\n",
    "            PD_simulations = np.empty(shape=(len(per_ind_params), n_times))\n",
    "            for idd, patient_parameters in enumerate(per_ind_params):\n",
    "                # avg_inferred = np.insert(avg_inferred, 1, PK_opt_params[0]) # Clearance\n",
    "                ind_param = patient_parameters.copy()\n",
    "                ind_param = np.insert(ind_param, 3, PK_opt_params[3]) # Periferal Parameters\n",
    "                ind_param = np.insert(ind_param, 4, PK_opt_params[4]) # Periferal Parameters\n",
    "                ind_param = np.insert(ind_param, 6, 0) # Nonsense paremeter\n",
    "                ind_param = np.insert(ind_param, -1, PK_opt_params[-1]) # PK Noise parameter\n",
    "                ind_sim = PKPD_model.simulate(\n",
    "                    ind_param[:-2],\n",
    "                    more_PK_times+dose_time\n",
    "                )[0]\n",
    "                PK_simulations[idd] = PK_noise_model.sample(\n",
    "                    ind_param[-2:-1], ind_sim)[:, 0]\n",
    "                ind_sim = PKPD_model.simulate(\n",
    "                    ind_param[:-2],\n",
    "                    more_PD_times + dose_time\n",
    "                )[1]\n",
    "                PD_simulations[idd] = PD_noise_model.sample(\n",
    "                    ind_param[-1:], ind_sim)[:, 0]\n",
    "            \n",
    "            # Plot the variability\n",
    "            fifth = np.percentile(PK_simulations, q=5, axis=0)\n",
    "            ninety_fifth = np.percentile(PK_simulations, q=95, axis=0)\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=np.hstack([more_PK_times, more_PK_times[::-1]]),\n",
    "                    y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                    line=dict(\n",
    "                        width=0,\n",
    "                        color=ind_colours[i, int(n_ids_data/2)]\n",
    "                    ),\n",
    "                    fill='toself',\n",
    "                    name='Population model',\n",
    "                    text=r\"90% bulk probability\",\n",
    "                    hoverinfo='text',\n",
    "                    legendgroup= group,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col\n",
    "            )\n",
    "            \n",
    "        # Plot the variability\n",
    "        fifth = np.percentile(PD_simulations, q=5, axis=0)\n",
    "        ninety_fifth = np.percentile(PD_simulations, q=95, axis=0)\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.hstack([more_PD_times, more_PD_times[::-1]]),\n",
    "                y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                line=dict(\n",
    "                    width=0,\n",
    "                    color=ind_colours[i, int(n_ids_data/2)]\n",
    "                ),\n",
    "                fill='toself',\n",
    "                name='Population model',\n",
    "                text=r\"90% bulk probability\",\n",
    "                hoverinfo='text',\n",
    "                legendgroup= group,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row,\n",
    "            col=col\n",
    "        )\n",
    "    if run == 0:\n",
    "        axis = ''\n",
    "    else:\n",
    "        axis = str(run+1)\n",
    "    fig1['layout']['yaxis'+axis].update(type=\"log\", minor=dict(dtick='D1', showgrid=True), dtick = 1, title_text = PK_y_label)\n",
    "    fig1['layout']['xaxis'+axis].update(dtick = 1, title_text = x_label)\n",
    "    fig2['layout']['yaxis'+axis].update(dtick = 250, title_text = PD_y_label)\n",
    "    fig2['layout']['xaxis'+axis].update(dtick = 72, minor=dict(dtick=24, showgrid=True), title_text = x_label)\n",
    "\n",
    "fig1.update_layout(\n",
    "    width=1100,\n",
    "    height=750,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig2.update_layout(\n",
    "    width=1100,\n",
    "    height=750,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig1.write_image(PD_image_file+\"/PK_MCMC_runs_graph_excl_Perif_PKnoise.svg\")\n",
    "fig2.write_image(PD_image_file+\"/PD_MCMC_runs_graph_excl_Perif_PKnoise.svg\")\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from math import floor\n",
    "\n",
    "n_times = 1000\n",
    "n_samples_per = 100  # number of samples to select for determining percentiles\n",
    "n_ids = 100  # number of ids to generate per sample for determining percentiles\n",
    "\n",
    "PK_time_span = df.loc[df[\"Observable\"] == \"PK_central.drug_concentration\"][\"Time\"].max()\n",
    "PD_time_span = df.loc[df[\"Observable\"] == \"circulating.R\"][\"Time\"].max()\n",
    "more_PK_times = np.linspace(\n",
    "    start=0, stop=1.01*(PK_time_span-dose_time), num=n_times\n",
    ")\n",
    "more_PD_times = np.linspace(\n",
    "    start=-dose_time, stop=1.01*(PD_time_span-dose_time), num=n_times\n",
    ")\n",
    "\n",
    "# Plot the PK Observations\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "mean_samples = main_samples.mean(dim=[\"draw\", \"chain\"])\n",
    "avg_inferred = np.asarray(mean_samples.drop(['PK_central.V_c']).to_array()).flatten()\n",
    "# avg_inferred = np.insert(avg_inferred, 1, PK_opt_params[0]) # Clearance\n",
    "avg_inferred[2] = np.exp(avg_inferred[2])                    # V_c mean\n",
    "avg_inferred = np.delete(avg_inferred, [3])                  # log V_c std.\n",
    "avg_inferred = np.insert(avg_inferred, 3, PK_opt_params[3])  # Periferal Parameters\n",
    "avg_inferred = np.insert(avg_inferred, 4, PK_opt_params[4])  # Periferal Parameters\n",
    "avg_inferred = np.insert(avg_inferred, 6, 0)                 # Nonsense paremeter\n",
    "avg_inferred = np.insert(avg_inferred, -1, PK_opt_params[-1])  # PK Noise parameter\n",
    "\n",
    "\n",
    "# sim_ind_params = population_model.sample(\n",
    "#     parameters=inferred_pop_params,\n",
    "#     n_samples=n_ids\n",
    "# )\n",
    "\n",
    "per_ind_params = np.empty((0, 7))\n",
    "per_samples = az.extract(main_samples, num_samples=n_samples_per)\n",
    "for s in per_samples.coords['sample']:\n",
    "    param = np.asarray(\n",
    "        per_samples.drop(['PK_central.V_c']).sel(sample=s).to_array()\n",
    "    ).flatten()\n",
    "    per_ind_params = np.concatenate((per_ind_params, population_model.sample(\n",
    "        parameters=param,\n",
    "        n_samples=n_ids\n",
    "    )), axis=0)\n",
    "\n",
    "# Plot the population model for each dose\n",
    "for i, group in enumerate(dose_groups):\n",
    "    # Simulate and Plot from the population mean\n",
    "    amt = dose_amts[i]\n",
    "    PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "    more_PK_values = PKPD_model.simulate(\n",
    "        avg_inferred[:-2],\n",
    "        more_PK_times+dose_time\n",
    "    )[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=more_PK_times,\n",
    "            y=more_PK_values,\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=ind_colours[i, int(n_ids_data/2)],\n",
    "                dash='dash'\n",
    "            ),\n",
    "            name='Typical simulation',\n",
    "            legendgroup=group,\n",
    "            # legendgrouptitle = {'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1\n",
    "    )\n",
    "    more_PD_values = PKPD_model.simulate(avg_inferred[:-2], more_PD_times)[1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=more_PD_times,\n",
    "            y=more_PD_values,\n",
    "            mode='lines',\n",
    "            line=dict(\n",
    "                color=ind_colours[i, int(n_ids_data/2)],\n",
    "                dash='dash'\n",
    "            ),\n",
    "            name='Typical simulation',\n",
    "            legendgroup=group,\n",
    "            legendgrouptitle={'text': 'Dose '+str(group)+' '+dose_unit},\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2\n",
    "    )\n",
    "    for j, patient in enumerate(df.loc[df['Dose group'] == group]['ID'].unique()):\n",
    "        ind_dose = df.loc[(df['ID']==patient) & df['Observable'].isna()]\n",
    "        PKPD_model.set_dosing_regimen(\n",
    "            ind_dose['Dose'].iat[0],\n",
    "            start=dose_time,\n",
    "            period=0\n",
    "        )\n",
    "        ind_real_params = avg_inferred.copy()\n",
    "        ind_Vc = mean_samples['PK_central.V_c'].sel(individual=str(patient))\n",
    "        ind_real_params[2] = ind_Vc.item()\n",
    "        if group != 0.0:\n",
    "            individual_PK_values = PKPD_model.simulate(\n",
    "                ind_real_params[:-2],\n",
    "                more_PK_times+dose_time\n",
    "            )[0]\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=more_PK_times,\n",
    "                    y=individual_PK_values,\n",
    "                    name='Individual simulation',\n",
    "                    legendgroup=group,\n",
    "                    showlegend=False,\n",
    "                    mode=\"lines\",\n",
    "                    line=go.scatter.Line(\n",
    "                        color=ind_colours[i, j],\n",
    "                        width=0.5\n",
    "                    ),\n",
    "                    opacity=0.5,\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1\n",
    "            )\n",
    "            ind_data = df_PK_graph.loc[df_PK_graph['ID'] == patient]\n",
    "            x_data = ind_data[x_label] - dose_time\n",
    "            y_data = ind_data[PK_y_label]\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_data,\n",
    "                y=y_data,\n",
    "                mode='markers',\n",
    "                marker_color=ind_colours[i, j],\n",
    "                name='Data',\n",
    "                legendgroup=group,\n",
    "                showlegend=False,\n",
    "            ), row=1, col=1)\n",
    "        individual_PD_values = PKPD_model.simulate(\n",
    "            ind_real_params[:-2],\n",
    "            more_PD_times+dose_time\n",
    "        )[1]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=more_PD_times,\n",
    "                y=individual_PD_values,\n",
    "                name='Individual simulation',\n",
    "                legendgroup=group,\n",
    "                showlegend=False,\n",
    "                mode=\"lines\",\n",
    "                line=go.scatter.Line(\n",
    "                    color=ind_colours[i, j],\n",
    "                    width=0.5\n",
    "                ),\n",
    "                opacity=0.5,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2\n",
    "        )\n",
    "        x_data = df_PD_graph.loc[df_PD_graph['ID'] == patient][x_label] - dose_time\n",
    "        y_data = df_PD_graph.loc[df_PD_graph['ID'] == patient][PD_y_label]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_data,\n",
    "                y=y_data,\n",
    "                mode='markers',\n",
    "                marker_color=ind_colours[i, j],\n",
    "                name='Data',\n",
    "                legendgroup=group,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2\n",
    "        )\n",
    "\n",
    "    PKPD_model.set_dosing_regimen(amt, start=dose_time, period=0)\n",
    "    if group != 0.0:\n",
    "        # Find 5th to 95th percentile of population distribution\n",
    "        PK_simulations = np.empty(shape=(len(per_ind_params), n_times))\n",
    "        PD_simulations = np.empty(shape=(len(per_ind_params), n_times))\n",
    "        for idd, patient_parameters in enumerate(per_ind_params):\n",
    "            # avg_inferred = np.insert(avg_inferred, 1, PK_opt_params[0])  # Clearance\n",
    "            ind_param = patient_parameters.copy()\n",
    "            ind_param = np.insert(ind_param, 3, PK_opt_params[3])  # Periferal Parameters\n",
    "            ind_param = np.insert(ind_param, 4, PK_opt_params[4])  # Periferal Parameters\n",
    "            ind_param = np.insert(ind_param, 6, 0)                 # Nonsense paremeter\n",
    "            ind_param = np.insert(ind_param, -1, PK_opt_params[-1])  # PK Noise parameter\n",
    "            ind_sim = PKPD_model.simulate(\n",
    "                ind_param[:-2],\n",
    "                more_PK_times+dose_time\n",
    "            )[0]\n",
    "            PK_simulations[idd] = PK_noise_model.sample(\n",
    "                ind_param[-2:-1], ind_sim)[:, 0]\n",
    "            ind_sim = PKPD_model.simulate(\n",
    "                ind_param[:-2],\n",
    "                more_PD_times + dose_time\n",
    "            )[1]\n",
    "            PD_simulations[idd] = PD_noise_model.sample(\n",
    "                ind_param[-1:], ind_sim\n",
    "            )[:, 0]\n",
    "\n",
    "        # Plot the variability\n",
    "        fifth = np.percentile(PK_simulations, q=5, axis=0)\n",
    "        ninety_fifth = np.percentile(PK_simulations, q=95, axis=0)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.hstack([more_PK_times, more_PK_times[::-1]]),\n",
    "                y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "                line=dict(\n",
    "                    width=0,\n",
    "                    color=ind_colours[i, int(n_ids_data/2)]\n",
    "                ),\n",
    "                fill='toself',\n",
    "                name='Population model',\n",
    "                text=r\"90% bulk probability\",\n",
    "                hoverinfo='text',\n",
    "                legendgroup=group,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1\n",
    "        )\n",
    "\n",
    "    # Plot the variability\n",
    "    fifth = np.percentile(PD_simulations, q=5, axis=0)\n",
    "    ninety_fifth = np.percentile(PD_simulations, q=95, axis=0)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.hstack([more_PD_times, more_PD_times[::-1]]),\n",
    "            y=np.hstack([fifth, ninety_fifth[::-1]]),\n",
    "            line=dict(\n",
    "                width=0,\n",
    "                color=ind_colours[i, int(n_ids_data/2)]\n",
    "            ),\n",
    "            fill='toself',\n",
    "            name='Population model',\n",
    "            text=r\"90% bulk probability\",\n",
    "            hoverinfo='text',\n",
    "            legendgroup=group,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2\n",
    "    )\n",
    "fig['layout']['yaxis'].update(\n",
    "    type=\"log\", minor=dict(dtick='D1', showgrid=True), dtick=1, title_text=PK_y_label\n",
    ")\n",
    "fig['layout']['xaxis'].update(dtick=1, title_text=x_label)\n",
    "fig['layout']['yaxis2'].update(dtick=250, title_text=PD_y_label)\n",
    "fig['layout']['xaxis2'].update(\n",
    "    dtick=72, minor=dict(dtick=24, showgrid=True), title_text=x_label\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.write_image(\n",
    "    PD_image_file+\"/PKPD_MCMC_tot_graph_excl_Perif_PKnoise.svg\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import arviz as az\n",
    "log_likelihood = problem.get_log_posterior().get_log_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(posterior_samples.data_vars)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointwiseLikelihood():\n",
    "\n",
    "    def __init__(self, log_likelihood, data) -> None:\n",
    "        self.log_likelihood = log_likelihood\n",
    "        self.data = data\n",
    "        self.ids = np.asarray(data[\"ID\"].unique())\n",
    "        self.n_obs_points = len(data.loc[(data[\"ID\"]==self.ids[0]) & data[\"Value\"].notna()])\n",
    "        self.reset_pwll()\n",
    "\n",
    "    def reset_pwll(self):\n",
    "        self.pwlls = np.empty((0, len(self.ids), self.n_obs_points))\n",
    "\n",
    "    def add_pwll(self, parameters):\n",
    "        pwll = np.asarray(self.log_likelihood.compute_pointwise_ll(parameters, per_individual=False))\n",
    "        pwll = pwll.reshape((1, len(self.ids), self.n_obs_points))\n",
    "        self.pwlls = np.append(self.pwlls, pwll, axis=0)\n",
    "\n",
    "    def create_pwlls(self, samples):\n",
    "        self.reset_pwll()\n",
    "        # add pointwise likelihood for each parameter sample\n",
    "        for param in samples:\n",
    "            self.add_pwll(param)\n",
    "            # check if it agrees with loglikelihood\n",
    "            sum_pw = np.sum(self.pwlls[-1])\n",
    "            ll = self.log_likelihood(param)\n",
    "            if np.isinf(sum_pw):\n",
    "                if not np.isinf(sum_pw):\n",
    "                    raise ValueError(\"pointwise log-likelihoods do not sum to log-likelihood, \"+str(sum_pw)+\"!=\"+str(ll))\n",
    "            elif np.abs((sum_pw-ll)/ll) > 1e-1:\n",
    "                    raise ValueError(\"pointwise log-likelihoods do not sum to log-likelihood, \"+str(sum_pw)+\"!=\"+str(ll))\n",
    "        return self.pwlls\n",
    "    \n",
    "    def get_inference_data(self, samples):\n",
    "        posterior = az.convert_to_inference_data(samples, group='posterior')\n",
    "        \n",
    "        obs_df = df.copy()\n",
    "        obs_df = obs_df.dropna(subset=['Observable']).sort_values(['ID', 'Time', 'Observable'])\n",
    "        obs_df[\"Points\"] = (\n",
    "            obs_df['Observable'].astype(str)+\n",
    "            np.asarray([\" - \"]*len(obs_df)).astype(str) +\n",
    "            obs_df['Time'].astype(str)\n",
    "        )\n",
    "        obs_df = obs_df[[\"ID\", \"Points\", \"Value\"]]\n",
    "        obs_df = obs_df.rename(columns={\"ID\": 'Individual'})\n",
    "        obs_points = obs_df[\"Points\"]\n",
    "        obs_df = obs_df.set_index(['Individual', \"Points\"])\n",
    "        observed = az.convert_to_inference_data(\n",
    "            obs_df.to_xarray(),\n",
    "            group='observed_data'\n",
    "        )\n",
    "\n",
    "        const_df = df.copy()\n",
    "        const_df = const_df.dropna(subset=['Dose']).sort_values(['ID', 'Time'])\n",
    "        const_df = const_df[['ID', \"Time\", \"Dose group\", \"Duration\", \"Dose\"]]\n",
    "        const_df = const_df.rename(columns={'ID': 'Individual'})\n",
    "        const_df = const_df.set_index(['Individual', \"Time\"])\n",
    "        constant = az.convert_to_inference_data(\n",
    "            obs_df.to_xarray(),\n",
    "            group='constant_data'\n",
    "        )\n",
    "        ids = df[\"ID\"].unique() # samples.coords[\"individual\"]\n",
    "        if isinstance(samples, (xr.Dataset, az.InferenceData)):\n",
    "            pop_param_names = [var for var in posterior_samples.data_vars if \" \" in var]\n",
    "            pop_samples = az.extract(posterior_samples, var_names=pop_param_names)\n",
    "            sample_coords = pop_samples.coords[\"sample\"]\n",
    "            try:\n",
    "                ind_samples = az.extract(posterior_samples, var_names=['~' + x for x in pop_param_names])\n",
    "            except KeyError:\n",
    "                ind_samples = np.empty((0, len(sample_coords)))\n",
    "            if isinstance(ind_samples, xr.Dataset):\n",
    "                flat_ind_samples = np.asarray(ind_samples[list(ind_samples.data_vars)[0]])\n",
    "                for var in list(ind_samples.data_vars)[1:]:\n",
    "                    flat_ind_samples = np.insert(flat_ind_samples, range(1, n_ids_data+1), ind_samples[var], axis=0)\n",
    "                ind_samples = flat_ind_samples\n",
    "            if isinstance(pop_samples, xr.Dataset):\n",
    "                pop_samples = pop_samples.to_array()\n",
    "            numpy_samples = np.concatenate((ind_samples, np.asarray(pop_samples))).transpose()\n",
    "        else:\n",
    "            numpy_samples = np.asarray(samples)\n",
    "            sample_coords = np.arange(numpy_samples.shape[0])\n",
    "        pwlls = np.asarray(np.split(self.create_pwlls(numpy_samples), len(samples.coords[\"draw\"]), axis=0))\n",
    "        pwlls = pwlls.transpose((1, 0, 2, 3))\n",
    "        pointwise = {\"pointwise log-likelihooods\": pwlls}\n",
    "        print(pointwise[\"pointwise log-likelihooods\"].shape)\n",
    "        coords = {\"individual\": ids, \"Points\": obs_points.unique()}\n",
    "        dims = {\"pointwise log-likelihooods\": [\"individual\", \"Points\"]}\n",
    "        likelihood = az.convert_to_inference_data(pointwise, coords=coords, dims=dims, group='log_likelihood')\n",
    "\n",
    "        inference_data = az.concat(likelihood, posterior, observed, constant)\n",
    "        return inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = [V_c_approx]*(n_ids_data*3) + [\n",
    "    0.5*PD_bounds[0,0]+0.5*PD_bounds[1,0],      # S\n",
    "    cl_approx,                                 # Clearance\n",
    "    np.log(V_c_approx),                         # Log mean of central volume\n",
    "    0.1,                                        # Log std. of central volume\n",
    "#     cl_approx*np.random.random(),             # Periferal compartment transfer\n",
    "#     V_c_approx*np.random.random(),            # Periferal compartment volume\n",
    "    R_0_approx,                                 # R_0\n",
    "    1,                                          # gamma\n",
    "    MTT_approx,                                 # MTT\n",
    "#     0.1,                                      # PK Noise parameter\n",
    "    0.1*R_0_approx*np.random.random(),          # PD Noise parameter\n",
    "]\n",
    "\n",
    "pw_ll = PointwiseLikelihood(log_likelihood, df)\n",
    "pw_ll.add_pwll(start_point)\n",
    "print(np.sum(pw_ll.pwlls), log_likelihood(start_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = xr.open_dataset(PD_data_file+drug+\"/\"+PD_pop_model_file+fixed_file+\"_samples.nc\").load()\n",
    "inference_data = pw_ll.get_inference_data(posterior_samples)\n",
    "az.to_netcdf(inference_data, PD_data_file+drug+\"/\"+PD_pop_model_file+fixed_file+\"_inference_obj.nc\")\n",
    "posterior_samples.close()\n",
    "inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Pointwise posterior samples\n",
    "import xarray as xr\n",
    "import arviz as az\n",
    "model_types = [\"fixed_effects\", \"pop_V_c\", \"pop_V_c_R_0\"]\n",
    "num_samples = 1500  # number of wanted final samples from all runs\n",
    "compare_dict = {}\n",
    "\n",
    "\n",
    "# For mixed effects model\n",
    "for model_type in model_types:\n",
    "    print('----------------------------------------------------------------------------------')\n",
    "    print(model_type)\n",
    "    inference_data = az.from_netcdf(PD_data_file+drug+\"/\"+model_type+fixed_file+\"_inference_obj.nc\")\n",
    "    compare_dict[model_type] = inference_data\n",
    "\n",
    "# compare_dict\n",
    "az.compare(compare_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(compare_dict, ic=\"waic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(compare_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
